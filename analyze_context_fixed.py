#!/usr/bin/env python3
"""
–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–º AI –∞–Ω–∞–ª–∏–∑–æ–º –¥–ª—è Ollama
"""

import json
import re
import yaml
import requests
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from collections import Counter

class ContextAnalyzerFixed:
    def __init__(self):
        self.context_file = Path('translation_context.yaml')
        self.analysis_cache = Path('context/analysis_cache.json')
        self.analysis_cache.parent.mkdir(exist_ok=True)
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ Ollama
        self.ollama_base = 'http://localhost:11434'
        self.model = 'llama3.2:3b'
        
        # –°–ª–æ–≤–∞—Ä–∏ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–∞ —Ç–µ–∫—Å—Ç–∞
        self.technical_markers = {
            'it': ['software', 'code', 'algorithm', 'database', 'API', 'framework', 
                   'programming', 'development', 'deploy', 'server', 'backend', 'frontend'],
            'engineering': ['design', 'specification', 'requirement', 'system', 'architecture',
                           'component', 'module', 'interface', 'implementation'],
            'management': ['employee', 'worker', 'manager', 'organization', 'workplace',
                          'motivation', 'satisfaction', 'engagement', 'productivity',
                          'leadership', 'team', 'performance', 'job', 'career'],
            'psychology': ['behavior', 'motivation', 'satisfaction', 'engagement', 'meaning',
                          'psychology', 'attitude', 'human nature', 'perception'],
            'business': ['company', 'CEO', 'profit', 'market', 'customer', 'strategy',
                        'revenue', 'business', 'corporation', 'enterprise', 'industry'],
            'science': ['research', 'hypothesis', 'experiment', 'analysis', 'data', 
                       'methodology', 'results', 'conclusion', 'theory']
        }
        
        self.style_indicators = {
            'formal': ['therefore', 'furthermore', 'consequently', 'nevertheless', 
                      'whereas', 'hereby', 'pursuant'],
            'informal': ["let's", "you'll", "we'll", "don't", "won't", "can't", 
                        'gonna', 'wanna', 'kinda'],
            'academic': ['abstract', 'methodology', 'literature review', 'hypothesis',
                        'conclusion', 'references', 'citation', 'et al.'],
            'instructional': ['step 1', 'step 2', 'how to', 'tutorial', 'guide',
                             'follow these', 'make sure', 'be careful']
        }
    
    def call_ollama_directly(self, prompt: str) -> str:
        """–ü—Ä—è–º–æ–π –≤—ã–∑–æ–≤ Ollama API –±–µ–∑ OpenAI –∫–ª–∏–µ–Ω—Ç–∞"""
        
        try:
            response = requests.post(
                f'{self.ollama_base}/api/generate',
                json={
                    'model': self.model,
                    'prompt': prompt,
                    'stream': False,
                    'temperature': 0.1,
                    'options': {
                        'num_predict': 200,
                        'top_k': 10,
                        'top_p': 0.5
                    }
                },
                timeout=600  # 10 –º–∏–Ω—É—Ç - –∂–¥—ë–º —Å—Ç–æ–ª—å–∫–æ —Å–∫–æ–ª—å–∫–æ –Ω—É–∂–Ω–æ!
            )
            
            if response.status_code == 200:
                result = response.json()
                return result.get('response', '')
            else:
                print(f"–û—à–∏–±–∫–∞ Ollama: {response.status_code}")
                return ''
                
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –≤—ã–∑–æ–≤–∞ Ollama: {e}")
            return ''
    
    def analyze_with_ai(self, text_sample: str) -> Dict:
        """AI –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ –ø—Ä—è–º–æ–π –≤—ã–∑–æ–≤ Ollama"""
        
        # –û—á–µ–Ω—å –ø—Ä–æ—Å—Ç–æ–π –ø—Ä–æ–º–ø—Ç –¥–ª—è llama3.2:3b
        prompt = f"""Read this text: "{text_sample[:800]}"

This text discusses: work, employees, satisfaction, motivation, engagement in workplace.

What type of text is this? Choose one:
1. business (about work, management, organizations)
2. technical (about computers, programming)
3. academic (formal research paper)
4. fiction (story, novel)
5. general (other)

Answer with just the number (1, 2, 3, 4 or 5):"""
        
        print("ü§ñ –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ Ollama...")
        response = self.call_ollama_directly(prompt)
        
        if response:
            print(f"üìù –û—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω: {response.strip()}")
            
            # –ü–∞—Ä—Å–∏–º –ø—Ä–æ—Å—Ç–æ–π –æ—Ç–≤–µ—Ç
            response_lower = response.lower().strip()
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø (–º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–æ–º–µ—Ä –∏–ª–∏ —Å–ª–æ–≤–æ)
            if '1' in response_lower or 'business' in response_lower or 'management' in response_lower or 'work' in response_lower:
                text_type = 'business'
                domain = 'management'
            elif '2' in response_lower or 'technical' in response_lower or 'computer' in response_lower:
                text_type = 'technical'
                domain = 'it'
            elif '3' in response_lower or 'academic' in response_lower or 'research' in response_lower:
                text_type = 'academic'
                domain = 'science'
            elif '4' in response_lower or 'fiction' in response_lower or 'story' in response_lower:
                text_type = 'fiction'
                domain = 'general'
            else:
                text_type = 'general'
                domain = 'general'
            
            # –¢–µ–ø–µ—Ä—å —Å–ø—Ä–æ—Å–∏–º –ø—Ä–æ –∞—É–¥–∏—Ç–æ—Ä–∏—é
            audience_prompt = f"Who would read this {text_type} text? Answer with one word: managers, professionals, students, or general:"
            
            print("ü§ñ –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∞—É–¥–∏—Ç–æ—Ä–∏—é...")
            audience_response = self.call_ollama_directly(audience_prompt)
            
            audience = 'professionals'  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
            if audience_response:
                print(f"üìù –ê—É–¥–∏—Ç–æ—Ä–∏—è: {audience_response.strip()}")
                if 'manager' in audience_response.lower():
                    audience = 'managers'
                elif 'student' in audience_response.lower():
                    audience = 'students'
                elif 'general' in audience_response.lower():
                    audience = 'general'
            
            result = {
                'text_type': text_type,
                'domain': domain,
                'audience': audience
            }
            
            print(f"‚úÖ AI –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω: {result}")
            return result
        
        return {}
    
    def analyze_text_sample(self, text: str, sample_size: int = 5000) -> Dict:
        """–ë–∞–∑–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        
        sample = text[:sample_size] if len(text) > sample_size else text
        words = sample.lower().split()
        word_count = len(words)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Ç–µ–∫—Å—Ç–∞
        text_lower = sample.lower()
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∫–Ω–∏–≥—É –æ –º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç–µ/—Ä–∞–±–æ—Ç–µ
        work_markers = ['work', 'worker', 'employee', 'job', 'satisfaction', 
                       'engagement', 'motivation', 'workplace', 'organization']
        work_count = sum(1 for marker in work_markers if marker in text_lower)
        
        if work_count >= 4:
            text_type = 'business'
        else:
            text_type = 'general'
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –æ–±–ª–∞—Å—Ç—å
        domain_scores = {}
        for domain, markers in self.technical_markers.items():
            score = sum(1 for word in words if word in markers)
            if score > 0:
                domain_scores[domain] = score
        
        if 'management' in domain_scores and 'psychology' in domain_scores:
            if domain_scores['management'] > 3 or domain_scores['psychology'] > 2:
                domain = 'management'
        elif domain_scores:
            domain = max(domain_scores, key=domain_scores.get)
        else:
            domain = 'general'
        
        return {
            'text_type': text_type,
            'domain': domain,
            'audience': 'professionals'
        }
    
    def generate_system_prompt(self, analysis: Dict) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞"""
        
        prompt_parts = ["–¢—ã –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫ —Å –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ –Ω–∞ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫."]
        
        # –°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ –æ–±–ª–∞—Å—Ç–∏
        if analysis.get('domain') == 'management':
            prompt_parts.append("–°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è: –º–µ–Ω–µ–¥–∂–º–µ–Ω—Ç –∏ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–æ–Ω–Ω–∞—è –ø—Å–∏—Ö–æ–ª–æ–≥–∏—è.")
            prompt_parts.append("–ò—Å–ø–æ–ª—å–∑—É–π –ø—Ä–∏–Ω—è—Ç—É—é –≤ –†–æ—Å—Å–∏–∏ –±–∏–∑–Ω–µ—Å-—Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—é.")
        elif analysis.get('domain') == 'it':
            prompt_parts.append("–°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è: IT –∏ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –ü–û.")
            prompt_parts.append("–ò—Å–ø–æ–ª—å–∑—É–π —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—É—é —Ä–æ—Å—Å–∏–π—Å–∫—É—é IT-—Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—é.")
        elif analysis.get('domain') == 'psychology':
            prompt_parts.append("–°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è: –ø—Å–∏—Ö–æ–ª–æ–≥–∏—è –∏ –ø–æ–≤–µ–¥–µ–Ω–∏–µ —á–µ–ª–æ–≤–µ–∫–∞.")
            prompt_parts.append("–ò—Å–ø–æ–ª—å–∑—É–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—É—é –ø—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫—É—é —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—é.")
        
        # –°—Ç–∏–ª—å –¥–ª—è —Ç–∏–ø–∞ —Ç–µ–∫—Å—Ç–∞
        if analysis.get('text_type') == 'business':
            prompt_parts.append("–¢–µ–∫—Å—Ç: –±–∏–∑–Ω–µ—Å-–ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞ —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏ –∏ –∏—Å—Ç–æ—Ä–∏—è–º–∏.")
            prompt_parts.append("–°–æ—Ö—Ä–∞–Ω—è–π –∂–∏–≤–æ–π —Å—Ç–∏–ª—å –∏–∑–ª–æ–∂–µ–Ω–∏—è, –Ω–æ –∏—Å–ø–æ–ª—å–∑—É–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—É—é –ª–µ–∫—Å–∏–∫—É.")
        elif analysis.get('text_type') == 'academic':
            prompt_parts.append("–¢–µ–∫—Å—Ç: –∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∞—è –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞.")
            prompt_parts.append("–ò—Å–ø–æ–ª—å–∑—É–π —Ñ–æ—Ä–º–∞–ª—å–Ω—ã–π –∞–∫–∞–¥–µ–º–∏—á–µ—Å–∫–∏–π —Å—Ç–∏–ª—å.")
        
        # –ê—É–¥–∏—Ç–æ—Ä–∏—è
        if analysis.get('audience') == 'managers':
            prompt_parts.append("–ê—É–¥–∏—Ç–æ—Ä–∏—è: –º–µ–Ω–µ–¥–∂–µ—Ä—ã –∏ —Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª–∏.")
        elif analysis.get('audience') == 'professionals':
            prompt_parts.append("–ê—É–¥–∏—Ç–æ—Ä–∏—è: –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—ã –≤ —Å–≤–æ–µ–π –æ–±–ª–∞—Å—Ç–∏.")
        
        # –û–±—â–∏–µ –ø—Ä–∞–≤–∏–ª–∞
        prompt_parts.extend([
            "–°–æ—Ö—Ä–∞–Ω—è–π –≤—Å–µ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä—ã [IMAGE_XXX], [TABLE_XXX] –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π.",
            "–°–æ—Ö—Ä–∞–Ω—è–π —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞.",
            "–ü–µ—Ä–µ–≤–æ–¥–∏ —Ç–æ—á–Ω–æ, –Ω–æ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞."
        ])
        
        return " ".join(prompt_parts)
    
    def analyze_and_save(self, text_path: str = 'book.txt') -> Dict:
        """–ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        
        print("üìö –ê–ù–ê–õ–ò–ó –ö–û–ù–¢–ï–ö–°–¢–ê")
        print("=" * 60)
        
        # –ß–∏—Ç–∞–µ–º —Ç–µ–∫—Å—Ç
        with open(text_path, 'r', encoding='utf-8') as f:
            text = f.read()[:5000]
        
        # –ë–∞–∑–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑
        print("\n1Ô∏è‚É£ –ë–∞–∑–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑...")
        base_analysis = self.analyze_text_sample(text)
        print(f"   –¢–∏–ø: {base_analysis['text_type']}")
        print(f"   –û–±–ª–∞—Å—Ç—å: {base_analysis['domain']}")
        
        # AI –∞–Ω–∞–ª–∏–∑
        print("\n2Ô∏è‚É£ AI –∞–Ω–∞–ª–∏–∑ (llama3.2:3b)...")
        ai_analysis = self.analyze_with_ai(text)
        
        if ai_analysis:
            print(f"   –¢–∏–ø: {ai_analysis.get('text_type', '?')}")
            print(f"   –û–±–ª–∞—Å—Ç—å: {ai_analysis.get('domain', '?')}")
            print(f"   –¢–µ–º–∞: {ai_analysis.get('topic', '?')}")
        
        # –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (AI –∏–º–µ–µ—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –µ—Å–ª–∏ –µ—Å—Ç—å)
        final_analysis = {**base_analysis}
        if ai_analysis:
            final_analysis.update(ai_analysis)
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        system_prompt = self.generate_system_prompt(final_analysis)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        config = {
            'text_type': final_analysis.get('text_type', 'general'),
            'domain': final_analysis.get('domain', 'general'),
            'style': {
                'formality': 'neutral',
                'tone': 'professional',
                'audience': final_analysis.get('audience', 'professionals')
            },
            'system_prompt': system_prompt
        }
        
        with open(self.context_file, 'w', encoding='utf-8') as f:
            yaml.dump(config, f, allow_unicode=True, default_flow_style=False)
        
        print(f"\n‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ {self.context_file}")
        print(f"\nüìù –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç:")
        print("-" * 40)
        print(system_prompt)
        
        return config


def main():
    analyzer = ContextAnalyzerFixed()
    analyzer.analyze_and_save()


if __name__ == '__main__':
    main()