#!/usr/bin/env python3
"""
–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä –∫–Ω–∏–≥ —Å –∞–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–º —Ä–∞–∑–±–∏–µ–Ω–∏–µ–º –Ω–∞ –∫–æ—Ä–æ—Ç–∫–∏–µ –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã
–¥–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ –ø–µ—Ä–µ–≤–æ–¥–∞
"""

import json
import re
from pathlib import Path
from typing import List, Dict, Optional
import sys

class OptimizedBookExtractor:
    def __init__(self, book_file="book.txt", output_dir="extracted"):
        self.book_file = Path(book_file)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è —Ä–∞–∑–±–∏–µ–Ω–∏—è –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤
        self.max_words_per_paragraph = 75   # –ú–∞–∫—Å–∏–º—É–º —Å–ª–æ–≤ –≤ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–µ
        self.ideal_words_per_paragraph = 50  # –ò–¥–µ–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞
        
    def extract(self) -> bool:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è"""
        if not self.book_file.exists():
            print(f"‚ùå –§–∞–π–ª {self.book_file} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
            return False
        
        with open(self.book_file, 'r', encoding='utf-8') as f:
            full_text = f.read()
        
        print(f"üìñ –ó–∞–≥—Ä—É–∂–µ–Ω —Ç–µ–∫—Å—Ç: {len(full_text)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –≥–ª–∞–≤—ã
        chapters = self._detect_text_chapters(full_text)
        
        if not chapters:
            print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É –≥–ª–∞–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç")
            chapters = [{'title': 'Full Book', 'text': full_text}]
        
        print(f"üìö –ù–∞–π–¥–µ–Ω–æ –≥–ª–∞–≤: {len(chapters)}")
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—É—é –≥–ª–∞–≤—É
        total_words = 0
        chapter_list = []
        
        for i, chapter in enumerate(chapters):
            # –ê–≥—Ä–µ—Å—Å–∏–≤–Ω–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã
            paragraphs = self._smart_split_paragraphs(chapter['text'])
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º –ø—É—Å—Ç—ã–µ –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã
            paragraphs = [p.strip() for p in paragraphs if p.strip()]
            
            word_count = sum(len(p.split()) for p in paragraphs)
            total_words += word_count
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –≥–ª–∞–≤—ã
            chapter_data = {
                'number': i,
                'title': chapter['title'],
                'paragraphs': paragraphs,
                'paragraph_count': len(paragraphs),
                'word_count': word_count,
                'char_count': len(chapter['text']),
                'source_format': 'txt',
                'extraction_method': 'optimized_smart_split'
            }
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º
            chapter_file = self.output_dir / f"chapter_{i:03d}.json"
            with open(chapter_file, 'w', encoding='utf-8') as f:
                json.dump(chapter_data, f, ensure_ascii=False, indent=2)
            
            print(f"‚úÖ –ì–ª–∞–≤–∞ {i}: {chapter['title']}")
            print(f"   –ü–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤: {len(paragraphs)}")
            print(f"   –°–ª–æ–≤: {word_count}")
            
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ä–∞–∑–º–µ—Ä–æ–≤ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤
            para_sizes = [len(p.split()) for p in paragraphs]
            if para_sizes:
                avg_size = sum(para_sizes) / len(para_sizes)
                print(f"   –°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞: {avg_size:.0f} —Å–ª–æ–≤")
                print(f"   –ú–∞–∫—Å/–ú–∏–Ω: {max(para_sizes)}/{min(para_sizes)} —Å–ª–æ–≤")
            
            chapter_list.append({
                'number': i,
                'title': chapter['title'],
                'paragraph_count': len(paragraphs),
                'word_count': word_count
            })
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        metadata = {
            'total_chapters': len(chapters),
            'total_words': total_words,
            'chapters': chapter_list,
            'extraction_method': 'optimized_smart_split',
            'max_words_per_paragraph': self.max_words_per_paragraph,
            'ideal_words_per_paragraph': self.ideal_words_per_paragraph
        }
        
        metadata_file = self.output_dir / "metadata.json"
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        
        print(f"\nüìä –í—Å–µ–≥–æ –∏–∑–≤–ª–µ—á–µ–Ω–æ {total_words} —Å–ª–æ–≤")
        return True
    
    def _smart_split_paragraphs(self, text: str) -> List[str]:
        """
        –£–º–Ω–æ–µ —Ä–∞–∑–±–∏–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –∫–æ—Ä–æ—Ç–∫–∏–µ –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã
        
        –°—Ç—Ä–∞—Ç–µ–≥–∏—è:
        1. –°–Ω–∞—á–∞–ª–∞ —Ä–∞–∑–±–∏–≤–∞–µ–º –ø–æ –¥–≤–æ–π–Ω—ã–º –ø–µ—Ä–µ–Ω–æ—Å–∞–º (–µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã)
        2. –ó–∞—Ç–µ–º –¥–ª–∏–Ω–Ω—ã–µ –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã —Ä–∞–∑–±–∏–≤–∞–µ–º –ø–æ —Ç–æ—á–∫–∞–º –Ω–∞ –≥—Ä—É–ø–ø—ã –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        3. –û—á–µ–Ω—å –¥–ª–∏–Ω–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –º–æ–∂–Ω–æ —Ä–∞–∑–±–∏—Ç—å –ø–æ —Ç–æ—á–∫–∞–º —Å –∑–∞–ø—è—Ç–æ–π –∏–ª–∏ –¥–≤–æ–µ—Ç–æ—á–∏—è–º
        """
        # –ó–∞–º–µ–Ω—è–µ–º –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω–∞ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –º–∞—Ä–∫–µ—Ä—ã
        text = re.sub(r'\[IMAGE[_ ]\d+\]', '<IMAGE_PLACEHOLDER>', text)
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã
        natural_paragraphs = re.split(r'\n\s*\n', text)
        
        result_paragraphs = []
        
        for para in natural_paragraphs:
            para = para.strip()
            if not para:
                continue
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–º
            if '<IMAGE_PLACEHOLDER>' in para:
                # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä
                para = re.sub(r'<IMAGE_PLACEHOLDER>', '[IMAGE_001]', para)
                result_paragraphs.append(para)
                continue
            
            # –°—á–∏—Ç–∞–µ–º —Å–ª–æ–≤–∞
            words = len(para.split())
            
            if words <= self.max_words_per_paragraph:
                # –ü–∞—Ä–∞–≥—Ä–∞—Ñ —É–∂–µ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∫–æ—Ä–æ—Ç–∫–∏–π
                result_paragraphs.append(para)
            else:
                # –ù—É–∂–Ω–æ —Ä–∞–∑–±–∏—Ç—å –Ω–∞ –±–æ–ª–µ–µ –∫–æ—Ä–æ—Ç–∫–∏–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã
                sub_paragraphs = self._split_long_paragraph(para)
                result_paragraphs.extend(sub_paragraphs)
        
        return result_paragraphs
    
    def _split_long_paragraph(self, para: str) -> List[str]:
        """
        –†–∞–∑–±–∏–≤–∞–µ—Ç –¥–ª–∏–Ω–Ω—ã–π –ø–∞—Ä–∞–≥—Ä–∞—Ñ –Ω–∞ –∫–æ—Ä–æ—Ç–∫–∏–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã
        """
        # –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º (–ø–æ —Ç–æ—á–∫–∞–º, ! –∏ ?)
        # –ù–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ–∫—Ä–∞—â–µ–Ω–∏—è —Ç–∏–ø–∞ Dr., Mr., etc.
        sentences = self._split_into_sentences(para)
        
        if not sentences:
            return [para]
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –≤ –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
        result = []
        current_group = []
        current_words = 0
        
        for sentence in sentences:
            sentence = sentence.strip()
            if not sentence:
                continue
            
            sentence_words = len(sentence.split())
            
            # –ï—Å–ª–∏ –æ–¥–Ω–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ, –ø—Ä–æ–±—É–µ–º —Ä–∞–∑–±–∏—Ç—å –µ–≥–æ –¥–∞–ª—å—à–µ
            if sentence_words > self.max_words_per_paragraph:
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—É—â—É—é –≥—Ä—É–ø–ø—É
                if current_group:
                    result.append(' '.join(current_group))
                    current_group = []
                    current_words = 0
                
                # –†–∞–∑–±–∏–≤–∞–µ–º –¥–ª–∏–Ω–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ
                sub_parts = self._split_very_long_sentence(sentence)
                result.extend(sub_parts)
                continue
            
            # –†–µ—à–∞–µ–º, –¥–æ–±–∞–≤–∏—Ç—å –ª–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –≤ —Ç–µ–∫—É—â—É—é –≥—Ä—É–ø–ø—É
            if current_words + sentence_words > self.max_words_per_paragraph:
                # –ù–æ –µ—Å–ª–∏ —Ç–µ–∫—É—â–∞—è –≥—Ä—É–ø–ø–∞ —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∞—è, –¥–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ —Ä–∞–≤–Ω–æ
                if current_words < 30 and sentence_words < self.ideal_words_per_paragraph:
                    current_group.append(sentence)
                    current_words += sentence_words
                else:
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—É—â—É—é –≥—Ä—É–ø–ø—É –∏ –Ω–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤—É—é
                    if current_group:
                        result.append(' '.join(current_group))
                    current_group = [sentence]
                    current_words = sentence_words
            else:
                # –î–æ–±–∞–≤–ª—è–µ–º –∫ —Ç–µ–∫—É—â–µ–π –≥—Ä—É–ø–ø–µ
                current_group.append(sentence)
                current_words += sentence_words
                
                # –ï—Å–ª–∏ –¥–æ—Å—Ç–∏–≥–ª–∏ –∏–¥–µ–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞, –∑–∞–≤–µ—Ä—à–∞–µ–º –≥—Ä—É–ø–ø—É
                if current_words >= self.ideal_words_per_paragraph:
                    result.append(' '.join(current_group))
                    current_group = []
                    current_words = 0
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—Ç–∞—Ç–æ–∫
        if current_group:
            result.append(' '.join(current_group))
        
        return result
    
    def _split_into_sentences(self, text: str) -> List[str]:
        """
        –†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        """
        # –ó–∞—â–∏—â–∞–µ–º —Å–æ–∫—Ä–∞—â–µ–Ω–∏—è
        text = re.sub(r'Dr\.', 'Dr<DOT>', text)
        text = re.sub(r'Mr\.', 'Mr<DOT>', text)
        text = re.sub(r'Mrs\.', 'Mrs<DOT>', text)
        text = re.sub(r'Ms\.', 'Ms<DOT>', text)
        text = re.sub(r'Prof\.', 'Prof<DOT>', text)
        text = re.sub(r'Sr\.', 'Sr<DOT>', text)
        text = re.sub(r'Jr\.', 'Jr<DOT>', text)
        text = re.sub(r'Ph\.D', 'Ph<DOT>D', text)
        text = re.sub(r'M\.D', 'M<DOT>D', text)
        text = re.sub(r'B\.A', 'B<DOT>A', text)
        text = re.sub(r'M\.A', 'M<DOT>A', text)
        text = re.sub(r'B\.S', 'B<DOT>S', text)
        text = re.sub(r'Ph\.D\.', 'Ph<DOT>D<DOT>', text)
        text = re.sub(r'i\.e\.', 'i<DOT>e<DOT>', text)
        text = re.sub(r'e\.g\.', 'e<DOT>g<DOT>', text)
        text = re.sub(r'etc\.', 'etc<DOT>', text)
        text = re.sub(r'vs\.', 'vs<DOT>', text)
        text = re.sub(r'U\.S\.', 'U<DOT>S<DOT>', text)
        text = re.sub(r'U\.K\.', 'U<DOT>K<DOT>', text)
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ —Ç–æ—á–∫–∞–º, ! –∏ ?
        sentences = re.split(r'(?<=[.!?])\s+', text)
        
        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–æ—á–∫–∏ –≤ —Å–æ–∫—Ä–∞—â–µ–Ω–∏—è—Ö
        sentences = [s.replace('<DOT>', '.') for s in sentences]
        
        return sentences
    
    def _split_very_long_sentence(self, sentence: str) -> List[str]:
        """
        –†–∞–∑–±–∏–≤–∞–µ—Ç –æ—á–µ–Ω—å –¥–ª–∏–Ω–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –Ω–∞ —á–∞—Å—Ç–∏
        """
        # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–±–∏—Ç—å –ø–æ —Ç–æ—á–∫–µ —Å –∑–∞–ø—è—Ç–æ–π
        parts = sentence.split(';')
        if len(parts) > 1:
            result = []
            for part in parts:
                part = part.strip()
                if part:
                    # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ—á–∫—É —Å –∑–∞–ø—è—Ç–æ–π –æ–±—Ä–∞—Ç–Ω–æ
                    if part != parts[-1].strip():
                        part += ';'
                    result.append(part)
            return result
        
        # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–±–∏—Ç—å –ø–æ –¥–≤–æ–µ—Ç–æ—á–∏—é
        parts = sentence.split(':')
        if len(parts) > 1:
            result = []
            for i, part in enumerate(parts):
                part = part.strip()
                if part:
                    # –î–æ–±–∞–≤–ª—è–µ–º –¥–≤–æ–µ—Ç–æ—á–∏–µ –∫ –ø–µ—Ä–≤–æ–π —á–∞—Å—Ç–∏
                    if i == 0:
                        part += ':'
                    result.append(part)
            return result
        
        # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–±–∏—Ç—å –ø–æ –¥–ª–∏–Ω–Ω—ã–º —Å–ø–∏—Å–∫–∞–º —Å –∑–∞–ø—è—Ç—ã–º–∏
        if sentence.count(',') > 3:
            # –ò—â–µ–º –ø–æ–∑–∏—Ü–∏—é –¥–ª—è —Ä–∞–∑–±–∏–µ–Ω–∏—è –ø—Ä–∏–º–µ—Ä–Ω–æ –ø–æ—Å–µ—Ä–µ–¥–∏–Ω–µ
            words = sentence.split()
            mid_point = len(words) // 2
            
            # –ò—â–µ–º –±–ª–∏–∂–∞–π—à—É—é –∑–∞–ø—è—Ç—É—é –∫ —Å–µ—Ä–µ–¥–∏–Ω–µ
            current_pos = 0
            best_split = -1
            for i, word in enumerate(words):
                if ',' in word and abs(i - mid_point) < abs(best_split - mid_point):
                    best_split = i
            
            if best_split > 0:
                part1 = ' '.join(words[:best_split + 1])
                part2 = ' '.join(words[best_split + 1:])
                return [part1, part2]
        
        # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å
        return [sentence]
    
    def _detect_text_chapters(self, text: str) -> List[Dict]:
        """
        –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –≥–ª–∞–≤—ã –≤ —Ç–µ–∫—Å—Ç–µ
        """
        chapters = []
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –≥–ª–∞–≤
        patterns = [
            r'Chapter\s+(\d+)',
            r'CHAPTER\s+(\d+)',
            r'Chapter\s+([IVX]+)',
            r'Part\s+(\d+)',
            r'Section\s+(\d+)',
            r'^\s*(\d+)\s*\n',
            r'^\s*([IVX]+)\s*\n'
        ]
        
        # –ò—â–µ–º –≤—Å–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
        positions = []
        for pattern in patterns:
            for match in re.finditer(pattern, text, re.MULTILINE):
                positions.append((match.start(), match.group(0), match.group(1)))
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –ø–æ–∑–∏—Ü–∏–∏
        positions.sort(key=lambda x: x[0])
        
        # –£–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –±–ª–∏–∑–∫–∏—Ö –ø–æ–∑–∏—Ü–∏–π
        filtered_positions = []
        last_pos = -1000
        for pos, full_match, chapter_num in positions:
            if pos - last_pos > 50:
                filtered_positions.append((pos, full_match, chapter_num))
                last_pos = pos
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Ç–µ–∫—Å—Ç –¥–æ –ø–µ—Ä–≤–æ–π –≥–ª–∞–≤—ã (–≤–≤–µ–¥–µ–Ω–∏–µ)
        if filtered_positions and filtered_positions[0][0] > 100:
            intro_text = text[:filtered_positions[0][0]].strip()
            if intro_text:
                chapters.append({
                    'title': '–í–≤–µ–¥–µ–Ω–∏–µ',
                    'text': intro_text
                })
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –≥–ª–∞–≤—ã
        for i, (pos, full_match, chapter_num) in enumerate(filtered_positions):
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–Ω–µ—Ü –≥–ª–∞–≤—ã
            if i < len(filtered_positions) - 1:
                end_pos = filtered_positions[i + 1][0]
            else:
                end_pos = len(text)
            
            chapter_text = text[pos:end_pos].strip()
            
            # –£–±–∏—Ä–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –≥–ª–∞–≤—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞
            chapter_text = chapter_text.replace(full_match, '', 1).strip()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –Ω–∞–∑–≤–∞–Ω–∏—è
            first_words = chapter_text[:100].split()[:10]
            title_candidate = ' '.join(first_words[:5])
            
            # –ï—Å–ª–∏ –µ—Å—Ç—å —è–≤–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ (–∫–æ—Ä–æ—Ç–∫–∞—è —Å—Ç—Ä–æ–∫–∞ –≤ –Ω–∞—á–∞–ª–µ)
            lines = chapter_text.split('\n', 2)
            if len(lines) > 0 and len(lines[0]) < 100 and len(lines[0].split()) < 10:
                chapter_title = lines[0].strip()
                chapter_text = '\n'.join(lines[1:]) if len(lines) > 1 else ''
            else:
                chapter_title = f"–ì–ª–∞–≤–∞ {chapter_num}"
            
            chapters.append({
                'title': chapter_title,
                'text': chapter_text
            })
        
        # –ï—Å–ª–∏ –≥–ª–∞–≤—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, –Ω–æ —Ç–µ–∫—Å—Ç –µ—Å—Ç—å
        if not chapters and text.strip():
            chapters.append({
                'title': '–ü–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç',
                'text': text
            })
        
        return chapters

def main():
    print("üìö –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä –∫–Ω–∏–≥ v2.0")
    print("=" * 50)
    
    extractor = OptimizedBookExtractor()
    
    if extractor.extract():
        print("\n‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!")
    else:
        print("\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏")
        sys.exit(1)

if __name__ == "__main__":
    main()