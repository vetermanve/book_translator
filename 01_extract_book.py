#!/usr/bin/env python3

import fitz
import os
import json
import re
from pathlib import Path
from tqdm import tqdm
import hashlib


class FixedPDFExtractor:
    """–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä PDF —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Ä–∞–∑–±–∏–≤–∫–æ–π –Ω–∞ –≥–ª–∞–≤—ã"""
    
    def __init__(self, pdf_path, output_dir="extracted_fixed"):
        self.pdf_path = pdf_path
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        self.metadata = {
            "total_pages": 0,
            "chapters": [],
            "extraction_complete": False,
            "book_title": "",
            "book_info": {}
        }
        
    def extract_all(self):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤—Å–µ–≥–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –∏–∑ PDF —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Ä–∞–∑–±–∏–≤–∫–æ–π"""
        print("üìñ –û—Ç–∫—Ä—ã–≤–∞–µ–º PDF –¥–æ–∫—É–º–µ–Ω—Ç...")
        doc = fitz.open(self.pdf_path)
        self.metadata["total_pages"] = len(doc)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∫–Ω–∏–≥–∏
        self._extract_book_metadata(doc)
        
        # –ü–æ–ª—É—á–∞–µ–º –æ–≥–ª–∞–≤–ª–µ–Ω–∏–µ
        toc = doc.get_toc()
        
        all_text = []
        print("üìÑ –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç...")
        for page_num in tqdm(range(len(doc)), desc="–ß—Ç–µ–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü"):
            page = doc[page_num]
            text = page.get_text()
            all_text.append(text)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –≥–ª–∞–≤
        if toc and len(toc) > 0:
            print("üìö –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ–≥–ª–∞–≤–ª–µ–Ω–∏–µ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≥–ª–∞–≤...")
            chapters_data = self._smart_split_by_toc(all_text, toc, doc)
        else:
            print("üìä –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –≥–ª–∞–≤—ã –ø–æ 30 —Å—Ç—Ä–∞–Ω–∏—Ü...")
            chapters_data = self._split_by_pages(all_text, 30)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≥–ª–∞–≤—ã
        print("üíæ –°–æ—Ö—Ä–∞–Ω—è–µ–º –≥–ª–∞–≤—ã...")
        chapter_number = 0
        for chapter_data in tqdm(chapters_data, desc="–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≥–ª–∞–≤"):
            self._save_chapter(
                chapter_data["title"], 
                chapter_data["text"], 
                chapter_number,
                chapter_data.get("start_page", 0),
                chapter_data.get("end_page", 0)
            )
            
            self.metadata["chapters"].append({
                "number": chapter_number,
                "title": chapter_data["title"],
                "start_page": chapter_data.get("start_page", 0),
                "end_page": chapter_data.get("end_page", 0),
                "page_count": chapter_data.get("end_page", 0) - chapter_data.get("start_page", 0) + 1,
                "status": "extracted"
            })
            
            chapter_number += 1
        
        doc.close()
        
        self.metadata["extraction_complete"] = True
        self._save_metadata()
        
        print(f"\n‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
        print(f"   üìë –ì–ª–∞–≤: {len(self.metadata['chapters'])}")
        print(f"   üìÑ –°—Ç—Ä–∞–Ω–∏—Ü: {self.metadata['total_pages']}")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏
        self._verify_extraction()
        
        return self.metadata
    
    def _smart_split_by_toc(self, all_text, toc, doc):
        """–£–º–Ω–∞—è —Ä–∞–∑–±–∏–≤–∫–∞ –Ω–∞ –≥–ª–∞–≤—ã –ø–æ –æ–≥–ª–∞–≤–ª–µ–Ω–∏—é –±–µ–∑ –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–π"""
        chapters = []
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º TOC - –æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –≥–ª–∞–≤—ã –≤–µ—Ä—Ö–Ω–µ–≥–æ —É—Ä–æ–≤–Ω—è –∏ –≤–∞–∂–Ω—ã–µ —Ä–∞–∑–¥–µ–ª—ã
        filtered_toc = []
        
        for i, entry in enumerate(toc):
            level, title, page_num = entry
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –Ω–æ–º–µ—Ä —Å—Ç—Ä–∞–Ω–∏—Ü—ã PDF –≤ –∏–Ω–¥–µ–∫—Å Python (PDF –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å 1)
            page_index = page_num - 1
            
            # –û—Å—Ç–∞–≤–ª—è–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã —É—Ä–æ–≤–Ω—è 0-2 –¥–ª—è –±–æ–ª—å—à–µ–π –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏
            # –∏–ª–∏ —ç–ª–µ–º–µ–Ω—Ç—ã —Å –∫–ª—é—á–µ–≤—ã–º–∏ —Å–ª–æ–≤–∞–º–∏
            if level <= 2 or any(keyword in title.lower() for keyword in 
                                ['chapter', 'part', 'introduction', '–≥–ª–∞–≤–∞', '—á–∞—Å—Ç—å', 'appendix', 
                                 'process area', 'section']):
                filtered_toc.append((level, title, page_index))
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –º–µ–ª–∫–∏–µ —Ä–∞–∑–¥–µ–ª—ã
        MIN_PAGES = 2  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –≥–ª–∞–≤—ã (—É–º–µ–Ω—å—à–∞–µ–º –¥–ª—è –±–æ–ª—å—à–µ–π –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏)
        merged_toc = []
        
        i = 0
        while i < len(filtered_toc):
            current_level, current_title, current_page = filtered_toc[i]
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–Ω–µ—Ü —Ç–µ–∫—É—â–µ–π –≥–ª–∞–≤—ã
            if i + 1 < len(filtered_toc):
                next_page = filtered_toc[i + 1][2]
            else:
                next_page = len(all_text) - 1
            
            # –ï—Å–ª–∏ –≥–ª–∞–≤–∞ —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∞—è, –æ–±—ä–µ–¥–∏–Ω—è–µ–º —Å —Å–ª–µ–¥—É—é—â–∏–º–∏
            accumulated_title = current_title
            accumulated_start = current_page
            accumulated_end = next_page
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –º–∞–ª–µ–Ω—å–∫–∏–µ –≥–ª–∞–≤—ã
            while accumulated_end - accumulated_start < MIN_PAGES and i + 1 < len(filtered_toc):
                i += 1
                if i < len(filtered_toc):
                    # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω–µ—Ü
                    if i + 1 < len(filtered_toc):
                        accumulated_end = filtered_toc[i + 1][2]
                    else:
                        accumulated_end = len(all_text) - 1
                    
                    # –ï—Å–ª–∏ —ç—Ç–æ —Ä–∞–∑–¥–µ–ª —Ç–æ–≥–æ –∂–µ —É—Ä–æ–≤–Ω—è, –æ–±–Ω–æ–≤–ª—è–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ
                    if filtered_toc[i][0] <= current_level + 1:
                        if len(accumulated_title) < 100:
                            accumulated_title += f" / {filtered_toc[i][1]}"
            
            merged_toc.append((current_level, accumulated_title, accumulated_start, accumulated_end))
            i += 1
        
        # –°–æ–∑–¥–∞–µ–º –≥–ª–∞–≤—ã –±–µ–∑ –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–π
        for i, (level, title, start_page, end_page) in enumerate(merged_toc):
            # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –Ω–µ—Ç –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–π
            if i > 0 and start_page <= merged_toc[i-1][3]:
                start_page = merged_toc[i-1][3] + 1
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å –¥–∏–∞–ø–∞–∑–æ–Ω–∞
            if start_page < len(all_text) and end_page >= start_page:
                # –°–æ–±–∏—Ä–∞–µ–º —Ç–µ–∫—Å—Ç –≥–ª–∞–≤—ã
                chapter_text = '\n'.join(all_text[start_page:end_page + 1])
                
                chapters.append({
                    "title": self._clean_title(title),
                    "text": chapter_text,
                    "start_page": start_page,
                    "end_page": end_page
                })
        
        print(f"üìö –°–æ–∑–¥–∞–Ω–æ {len(chapters)} –≥–ª–∞–≤ –∏–∑ {len(toc)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –æ–≥–ª–∞–≤–ª–µ–Ω–∏—è")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–∫—Ä—ã—Ç–∏–µ
        covered_pages = set()
        for ch in chapters:
            for p in range(ch["start_page"], ch["end_page"] + 1):
                covered_pages.add(p)
        
        missing_pages = set(range(len(all_text))) - covered_pages
        if missing_pages:
            print(f"‚ö†Ô∏è –ù–µ–ø–æ–∫—Ä—ã—Ç—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {len(missing_pages)} –∏–∑ {len(all_text)}")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–ø–æ–∫—Ä—ã—Ç—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –∫ –±–ª–∏–∂–∞–π—à–∏–º –≥–ª–∞–≤–∞–º
            for page in sorted(missing_pages):
                # –ù–∞—Ö–æ–¥–∏–º –±–ª–∏–∂–∞–π—à—É—é –≥–ª–∞–≤—É
                for ch in chapters:
                    if ch["end_page"] == page - 1:
                        ch["end_page"] = page
                        ch["text"] += "\n" + all_text[page]
                        break
                    elif ch["start_page"] == page + 1:
                        ch["start_page"] = page
                        ch["text"] = all_text[page] + "\n" + ch["text"]
                        break
        
        return chapters
    
    def _split_by_pages(self, all_text, pages_per_chapter):
        """–†–∞–∑–±–∏–≤–∫–∞ –Ω–∞ –≥–ª–∞–≤—ã –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Å—Ç—Ä–∞–Ω–∏—Ü (–∑–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç)"""
        chapters = []
        
        for i in range(0, len(all_text), pages_per_chapter):
            start_page = i
            end_page = min(i + pages_per_chapter - 1, len(all_text) - 1)
            
            # –°–æ–±–∏—Ä–∞–µ–º —Ç–µ–∫—Å—Ç –≥–ª–∞–≤—ã
            chapter_text = '\n'.join(all_text[start_page:end_page + 1])
            
            # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫
            title = self._find_chapter_title(chapter_text, len(chapters))
            
            chapters.append({
                "title": title,
                "text": chapter_text,
                "start_page": start_page,
                "end_page": end_page
            })
        
        return chapters
    
    def _clean_title(self, title):
        """–û—á–∏—â–∞–µ—Ç –∑–∞–≥–æ–ª–æ–≤–æ–∫ –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤"""
        # –£–±–∏—Ä–∞–µ–º –Ω–æ–º–µ—Ä–∞ —Å—Ç—Ä–∞–Ω–∏—Ü –≤ –∫–æ–Ω—Ü–µ
        title = re.sub(r'\s*\d+\s*$', '', title)
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
        title = ' '.join(title.split())
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
        if len(title) > 150:
            title = title[:147] + "..."
        return title
    
    def _find_chapter_title(self, text, chapter_num):
        """–ü–æ–ø—ã—Ç–∫–∞ –Ω–∞–π—Ç–∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫ –≥–ª–∞–≤—ã"""
        lines = text.split('\n')[:20]
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
        patterns = [
            r"^(Chapter|CHAPTER|–ì–ª–∞–≤–∞)\s+(\d+|[IVX]+)",
            r"^(Part|PART|–ß–∞—Å—Ç—å)\s+(\d+|[IVX]+)",
            r"^(\d+\.)\s+[A-Z–ê-–Ø][a-z–∞-—è]+",
            r"^(Section|SECTION|–†–∞–∑–¥–µ–ª)\s+(\d+)",
        ]
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            for pattern in patterns:
                if re.match(pattern, line):
                    return self._clean_title(line)
            
            # –ï—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ –≤—ã–≥–ª—è–¥–∏—Ç –∫–∞–∫ –∑–∞–≥–æ–ª–æ–≤–æ–∫
            if (len(line) > 5 and len(line) < 100 and 
                not line.endswith('.') and 
                not line.endswith(',') and
                line[0].isupper()):
                words = line.split()
                if len(words) < 15:
                    return self._clean_title(line)
        
        return f"–ß–∞—Å—Ç—å {chapter_num + 1}"
    
    def _save_chapter(self, title, text, chapter_num, start_page, end_page):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≥–ª–∞–≤—ã –≤ JSON"""
        filename = f"chapter_{chapter_num:03d}.json"
        filepath = self.output_dir / filename
        
        # –û—á–∏—â–∞–µ–º —Ç–µ–∫—Å—Ç
        text = self._clean_text(text)
        
        # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ –∞–±–∑–∞—Ü—ã
        paragraphs = self._split_into_paragraphs(text)
        
        chapter_data = {
            "number": chapter_num,
            "title": title,
            "start_page": start_page,
            "end_page": end_page,
            "paragraphs": paragraphs,
            "word_count": len(text.split())
        }
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(chapter_data, f, ensure_ascii=False, indent=2)
    
    def _clean_text(self, text):
        """–û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –æ—Ç –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –ø–µ—Ä–µ–Ω–æ—Å–æ–≤ —Å—Ç—Ä–æ–∫"""
        # –£–¥–∞–ª—è–µ–º —Ç–æ–ª—å–∫–æ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã –∏ —Ç–∞–±—ã (–ù–ï –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫!)
        text = re.sub(r'[ \t]+', ' ', text)
        # –£–¥–∞–ª—è–µ–º –ø—Ä–æ–±–µ–ª—ã –≤ –Ω–∞—á–∞–ª–µ –∏ –∫–æ–Ω—Ü–µ —Å—Ç—Ä–æ–∫
        text = re.sub(r'\n[ \t]+', '\n', text)
        text = re.sub(r'[ \t]+\n', '\n', text)
        # –£–±–∏—Ä–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ (–Ω–æ –æ—Å—Ç–∞–≤–ª—è–µ–º –æ–¥–∏–Ω–æ—á–Ω—ã–µ –ø–µ—Ä–µ–Ω–æ—Å—ã!)
        text = re.sub(r'\n{4,}', '\n\n\n', text)
        return text.strip()
    
    def _split_into_paragraphs(self, text):
        """–†–∞–∑–±–∏–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –∞–±–∑–∞—Ü—ã —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏—Ö –ø–µ—Ä–µ–Ω–æ—Å–æ–≤"""
        # –†–∞–∑–¥–µ–ª—è–µ–º –ø–æ –¥–≤–æ–π–Ω—ã–º –ø–µ—Ä–µ–≤–æ–¥–∞–º —Å—Ç—Ä–æ–∫–∏
        paragraphs = text.split('\n\n')
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π –ø–∞—Ä–∞–≥—Ä–∞—Ñ, —Å–æ—Ö—Ä–∞–Ω—è—è –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –ø–µ—Ä–µ–Ω–æ—Å—ã
        cleaned_paragraphs = []
        for p in paragraphs:
            if p.strip():
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–¥–∏–Ω–æ—á–Ω—ã–µ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫ –≤–Ω—É—Ç—Ä–∏ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞
                # –£–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –≤ –Ω–∞—á–∞–ª–µ –∏ –∫–æ–Ω—Ü–µ
                cleaned_p = p.strip()
                if len(cleaned_p) > 10:  # –§–∏–ª—å—Ç—Ä—É–µ–º —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã
                    cleaned_paragraphs.append(cleaned_p)
        return cleaned_paragraphs
    
    def _extract_book_metadata(self, doc):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∫–Ω–∏–≥–∏"""
        metadata = doc.metadata
        if metadata:
            self.metadata["book_info"] = {
                "title": metadata.get("title", ""),
                "author": metadata.get("author", ""),
                "subject": metadata.get("subject", ""),
                "keywords": metadata.get("keywords", ""),
            }
    
    def _save_metadata(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö"""
        metadata_file = self.output_dir / "metadata.json"
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(self.metadata, f, ensure_ascii=False, indent=2)
    
    def _verify_extraction(self):
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è"""
        print("\nüîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏...")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–∫—Ä—ã—Ç–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü
        covered_pages = set()
        overlapping_pages = []
        
        for i, ch in enumerate(self.metadata["chapters"]):
            chapter_pages = set(range(ch["start_page"], ch["end_page"] + 1))
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–π
            overlap = covered_pages & chapter_pages
            if overlap:
                overlapping_pages.append((i, sorted(overlap)))
            
            covered_pages.update(chapter_pages)
        
        missing_pages = set(range(self.metadata["total_pages"])) - covered_pages
        
        if overlapping_pages:
            print(f"‚ö†Ô∏è –ù–∞–π–¥–µ–Ω—ã –ø–µ—Ä–µ–∫—Ä—ã–≤–∞—é—â–∏–µ—Å—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã:")
            for ch_num, pages in overlapping_pages[:5]:
                print(f"   –ì–ª–∞–≤–∞ {ch_num}: —Å—Ç—Ä–∞–Ω–∏—Ü—ã {pages[:10]}...")
        
        if missing_pages:
            print(f"‚ö†Ô∏è –ù–µ–ø–æ–∫—Ä—ã—Ç—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {sorted(missing_pages)[:20]}...")
        
        if not overlapping_pages and not missing_pages:
            print("‚úÖ –í—Å–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ø–æ–∫—Ä—ã—Ç—ã –±–µ–∑ –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–π")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        chapter_sizes = [ch["page_count"] for ch in self.metadata["chapters"]]
        print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –≥–ª–∞–≤:")
        print(f"   –°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä: {sum(chapter_sizes)/len(chapter_sizes):.1f} —Å—Ç—Ä–∞–Ω–∏—Ü")
        print(f"   –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π: {min(chapter_sizes)} —Å—Ç—Ä–∞–Ω–∏—Ü")
        print(f"   –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π: {max(chapter_sizes)} —Å—Ç—Ä–∞–Ω–∏—Ü")


if __name__ == "__main__":
    print("üöÄ –ó–∞–ø—É—Å–∫ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–≥–æ —ç–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä–∞ PDF...")
    print("")
    
    extractor = FixedPDFExtractor("book.pdf")
    metadata = extractor.extract_all()
    
    print(f"\n‚ú® –ì–æ—Ç–æ–≤–æ!")
    print(f"   –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ø–∞–ø–∫–µ extracted_fixed/")
    print(f"   –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å –ø–µ—Ä–µ–≤–æ–¥ —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π –≥–ª–∞–≤")