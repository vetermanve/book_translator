import json
import os
from pathlib import Path
import time
from typing import List, Dict
import re
from openai import OpenAI
# from dotenv import load_dotenv  # –£–±—Ä–∞–Ω–æ, —á–∏—Ç–∞–µ–º .env –Ω–∞–ø—Ä—è–º—É—é


class DeepSeekTranslator:
    def __init__(self, api_key=None):
        # –ó–∞–≥—Ä—É–∂–∞–µ–º API –∫–ª—é—á –∏–∑ .env —Ñ–∞–π–ª–∞
        if not api_key:
            env_file = Path('.env')
            if env_file.exists():
                with open(env_file) as f:
                    for line in f:
                        if line.startswith('DEEPSEEK_API_KEY='):
                            # –ü–æ–ª—É—á–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ—Å–ª–µ =
                            value = line.split('=', 1)[1].strip()
                            # –£–±–∏—Ä–∞–µ–º –∫–∞–≤—ã—á–∫–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
                            if value.startswith('"') and value.endswith('"'):
                                value = value[1:-1]
                            elif value.startswith("'") and value.endswith("'"):
                                value = value[1:-1]
                            api_key = value
                            break
        self.api_key = api_key or os.getenv("DEEPSEEK_API_KEY")
        if self.api_key:
            # DeepSeek –∏—Å–ø–æ–ª—å–∑—É–µ—Ç OpenAI-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π API
            self.client = OpenAI(
                api_key=self.api_key,
                base_url="https://api.deepseek.com/v1"
            )
        else:
            self.client = None
            print("–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: DeepSeek API –∫–ª—é—á –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        
        self.translations_dir = Path("translations")
        self.translations_dir.mkdir(exist_ok=True)
        
        # –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞
        self.tech_terms = {
            # –ü—Ä–æ—Ü–µ—Å—Å—ã –∏ –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏–∏
            "process": "–ø—Ä–æ—Ü–µ—Å—Å",
            "procedure": "–ø—Ä–æ—Ü–µ–¥—É—Ä–∞",
            "framework": "—Ñ—Ä–µ–π–º–≤–æ—Ä–∫",
            "methodology": "–º–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è",
            "approach": "–ø–æ–¥—Ö–æ–¥",
            "practice": "–ø—Ä–∞–∫—Ç–∏–∫–∞",
            "implementation": "—Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è",
            "deployment": "—Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏–µ",
            "integration": "–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è",
            
            # CMMI —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã
            "CMMI": "CMMI",
            "Capability Maturity Model": "–ú–æ–¥–µ–ª—å –∑—Ä–µ–ª–æ—Å—Ç–∏ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤",
            "maturity level": "—É—Ä–æ–≤–µ–Ω—å –∑—Ä–µ–ª–æ—Å—Ç–∏",
            "process area": "–æ–±–ª–∞—Å—Ç—å –ø—Ä–æ—Ü–µ—Å—Å–æ–≤",
            "specific goal": "–∫–æ–Ω–∫—Ä–µ—Ç–Ω–∞—è —Ü–µ–ª—å",
            "generic goal": "–æ–±—â–∞—è —Ü–µ–ª—å",
            "specific practice": "–∫–æ–Ω–∫—Ä–µ—Ç–Ω–∞—è –ø—Ä–∞–∫—Ç–∏–∫–∞",
            "generic practice": "–æ–±—â–∞—è –ø—Ä–∞–∫—Ç–∏–∫–∞",
            
            # –†–∞–∑—Ä–∞–±–æ—Ç–∫–∞ –ü–û
            "software": "–ø—Ä–æ–≥—Ä–∞–º–º–Ω–æ–µ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏–µ",
            "development": "—Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞",
            "requirement": "—Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ",
            "design": "–ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ",
            "testing": "—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ",
            "validation": "–≤–∞–ª–∏–¥–∞—Ü–∏—è",
            "verification": "–≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è",
            "configuration": "–∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è",
            "management": "—É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ",
            "quality": "–∫–∞—á–µ—Å—Ç–≤–æ",
            "assurance": "–æ–±–µ—Å–ø–µ—á–µ–Ω–∏–µ",
            
            # –û—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã
            "organization": "–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è",
            "project": "–ø—Ä–æ–µ–∫—Ç",
            "team": "–∫–æ–º–∞–Ω–¥–∞",
            "stakeholder": "–∑–∞–∏–Ω—Ç–µ—Ä–µ—Å–æ–≤–∞–Ω–Ω–∞—è —Å—Ç–æ—Ä–æ–Ω–∞",
            "customer": "–∑–∞–∫–∞–∑—á–∏–∫",
            "supplier": "–ø–æ—Å—Ç–∞–≤—â–∏–∫",
            "performance": "–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å",
            "measurement": "–∏–∑–º–µ—Ä–µ–Ω–∏–µ",
            "metric": "–º–µ—Ç—Ä–∏–∫–∞",
            "indicator": "–∏–Ω–¥–∏–∫–∞—Ç–æ—Ä"
        }
    
    def translate_chapter(self, chapter_data, context, use_api=True):
        if use_api and self.client:
            return self._translate_with_deepseek(chapter_data, context)
        else:
            return self._translate_local(chapter_data, context)
    
    def _translate_with_deepseek(self, chapter_data, context):
        translated_paragraphs = []
        
        system_prompt = self._create_system_prompt(context)
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –Ω–æ–≤—É—é —Å—Ç—Ä–∞—Ç–µ–≥–∏—é —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º: –≥—Ä—É–ø–ø—ã –ø–æ 3 –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
        paragraph_groups = self._group_paragraphs_with_context(chapter_data["paragraphs"], target_per_group=3)
        
        print(f"üìù –ü–µ—Ä–µ–≤–æ–¥ –≥–ª–∞–≤—ã '{chapter_data['title']}' ({len(paragraph_groups)} –≥—Ä—É–ø–ø –ø–æ 3 –∞–±–∑–∞—Ü–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º)")
        
        for group_idx, paragraph_group in enumerate(paragraph_groups):
            # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ –Ω–µ—Ç (—Ç–æ–ª—å–∫–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è)
            if not paragraph_group["translate_text"].strip():
                translated_paragraphs.extend(paragraph_group["to_translate"])
                continue
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –ø—Ä–æ–º–ø—Ç
            context_prompt = self._build_context_prompt(paragraph_group)
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞
            paragraph_with_placeholders = self._preserve_placeholders(paragraph_group["translate_text"])
            
            try:
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º DeepSeek –º–æ–¥–µ–ª—å
                response = self.client.chat.completions.create(
                    model="deepseek-chat",  # –ú–æ–¥–µ–ª—å DeepSeek
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": context_prompt}
                    ],
                    temperature=0.3,
                    max_tokens=3000
                )
                
                translated = response.choices[0].message.content
                translated = self._restore_placeholders(translated)
                translated = self._post_process_formatting(translated)
                
                # –†–∞–∑–±–∏–≤–∞–µ–º –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –Ω–∞ –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã
                translated_parts = translated.split('\n\n')
                
                # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–æ—Ä—è–¥–æ–∫ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ –¥–ª—è —Ç–µ–∫—É—â–µ–π –≥—Ä—É–ø–ø—ã
                result_paragraphs = []
                text_idx = 0
                
                for original_paragraph in paragraph_group["to_translate"]:
                    if original_paragraph.startswith("[IMAGE_"):
                        # –í—Å—Ç–∞–≤–ª—è–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫–∞–∫ –µ—Å—Ç—å
                        result_paragraphs.append(original_paragraph)
                    else:
                        # –í—Å—Ç–∞–≤–ª—è–µ–º –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
                        if text_idx < len(translated_parts):
                            result_paragraphs.append(translated_parts[text_idx])
                            text_idx += 1
                        else:
                            # –ï—Å–ª–∏ –ø–µ—Ä–µ–≤–æ–¥–æ–≤ –º–µ–Ω—å—à–µ —á–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∑–∞–ø–∞—Å–Ω–æ–π –ø–µ—Ä–µ–≤–æ–¥
                            result_paragraphs.append(self._fallback_translate(original_paragraph))
                
                translated_paragraphs.extend(result_paragraphs)
                
                # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                time.sleep(0.5)  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∑–∞–¥–µ—Ä–∂–∫—É –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
                
            except Exception as e:
                print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–≤–æ–¥–µ –≥—Ä—É–ø–ø—ã {group_idx}: {e}")
                # –ü—Ä–∏ –æ—à–∏–±–∫–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—ã–π –ø–µ—Ä–µ–≤–æ–¥
                for p in paragraph_group["to_translate"]:
                    translated_paragraphs.append(self._fallback_translate(p))
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ
        summary = self._generate_summary(translated_paragraphs)
        
        return {
            "number": chapter_data["number"],
            "title": self._translate_title(chapter_data["title"]),
            "paragraphs": translated_paragraphs,
            "summary": summary,
            "original_word_count": chapter_data["word_count"],
            "translator": "DeepSeek"
        }
    
    def translate_paragraph_group_with_context(self, paragraph_group, context):
        """–ü–µ—Ä–µ–≤–æ–¥ –æ–¥–Ω–æ–π –≥—Ä—É–ø–ø—ã –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º (–¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è)"""
        if not self.client:
            # Fallback –±–µ–∑ API
            result_paragraphs = []
            for p in paragraph_group["to_translate"]:
                if p.startswith("[IMAGE_"):
                    result_paragraphs.append(p)
                else:
                    result_paragraphs.append(self._fallback_translate(p))
            return result_paragraphs
        
        try:
            system_prompt = self._create_system_prompt(context)
            context_prompt = self._build_context_prompt(paragraph_group)
            
            response = self.client.chat.completions.create(
                model="deepseek-chat",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": context_prompt}
                ],
                temperature=0.3,
                max_tokens=3000
            )
            
            translated = response.choices[0].message.content
            translated = self._restore_placeholders(translated)
            translated = self._post_process_formatting(translated)
            
            # –†–∞–∑–±–∏–≤–∞–µ–º –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –Ω–∞ –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã
            translated_parts = translated.split('\n\n')
            
            # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–æ—Ä—è–¥–æ–∫ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
            result_paragraphs = []
            text_idx = 0
            
            for original_paragraph in paragraph_group["to_translate"]:
                if original_paragraph.startswith("[IMAGE_"):
                    result_paragraphs.append(original_paragraph)
                else:
                    if text_idx < len(translated_parts):
                        result_paragraphs.append(translated_parts[text_idx])
                        text_idx += 1
                    else:
                        result_paragraphs.append(self._fallback_translate(original_paragraph))
            
            return result_paragraphs
            
        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–≤–æ–¥–µ –≥—Ä—É–ø–ø—ã: {e}")
            # –ü—Ä–∏ –æ—à–∏–±–∫–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—ã–π –ø–µ—Ä–µ–≤–æ–¥
            result_paragraphs = []
            for p in paragraph_group["to_translate"]:
                if p.startswith("[IMAGE_"):
                    result_paragraphs.append(p)
                else:
                    result_paragraphs.append(self._fallback_translate(p))
            return result_paragraphs
    
    def _group_paragraphs(self, paragraphs, max_chars=1500):
        """–ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞"""
        groups = []
        current_group = []
        current_length = 0
        image_placeholders = []  # –ù–∞–∫–∞–ø–ª–∏–≤–∞–µ–º –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä—ã
        
        for paragraph in paragraphs:
            # –ï—Å–ª–∏ —ç—Ç–æ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è - –ø—Ä–æ—Å—Ç–æ –∑–∞–ø–æ–º–∏–Ω–∞–µ–º –µ–≥–æ
            if paragraph.startswith("[IMAGE_"):
                image_placeholders.append(paragraph)
            else:
                # –ï—Å–ª–∏ –±—ã–ª–∏ –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –¥–æ–±–∞–≤–ª—è–µ–º –∏—Ö –≤ —Ç–µ–∫—É—â—É—é –≥—Ä—É–ø–ø—É
                if image_placeholders:
                    current_group.extend(image_placeholders)
                    image_placeholders = []
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä –≥—Ä—É–ø–ø—ã
                if current_length + len(paragraph) > max_chars and current_group:
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—É—â—É—é –≥—Ä—É–ø–ø—É
                    groups.append({
                        "text": "\n\n".join([p for p in current_group if not p.startswith("[IMAGE_")]),
                        "paragraphs": current_group,
                        "has_images": any(p.startswith("[IMAGE_") for p in current_group)
                    })
                    current_group = []
                    current_length = 0
                
                current_group.append(paragraph)
                current_length += len(paragraph)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∫ –ø–æ—Å–ª–µ–¥–Ω–µ–π –≥—Ä—É–ø–ø–µ
        if image_placeholders:
            current_group.extend(image_placeholders)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –≥—Ä—É–ø–ø—É
        if current_group:
            groups.append({
                "text": "\n\n".join([p for p in current_group if not p.startswith("[IMAGE_")]),
                "paragraphs": current_group,
                "has_images": any(p.startswith("[IMAGE_") for p in current_group)
            })
        
        return groups
    
    def _group_paragraphs_with_context(self, paragraphs, target_per_group=3):
        """–ì—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º: 3 –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö + 3 –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞ + 3 —Å–ª–µ–¥—É—é—â–∏—Ö"""
        groups = []
        total_paragraphs = len(paragraphs)
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–æ target_per_group –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤ –∑–∞ —Ä–∞–∑
        for i in range(0, total_paragraphs, target_per_group):
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω—ã
            context_before_start = max(0, i - target_per_group)
            translate_start = i
            translate_end = min(i + target_per_group, total_paragraphs)
            context_after_end = min(translate_end + target_per_group, total_paragraphs)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∞—Å—Ç–∏
            context_before = paragraphs[context_before_start:translate_start] if context_before_start < translate_start else []
            to_translate = paragraphs[translate_start:translate_end]
            context_after = paragraphs[translate_end:context_after_end] if translate_end < context_after_end else []
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (–æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –≤ —Ü–µ–ª–µ–≤—ã—Ö –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞—Ö)
            context_before_text = [p for p in context_before if not p.startswith("[IMAGE_")]
            context_after_text = [p for p in context_after if not p.startswith("[IMAGE_")]
            
            group = {
                "index": len(groups),
                "translate_start": translate_start,
                "translate_end": translate_end,
                "context_before": context_before_text,
                "to_translate": to_translate,
                "context_after": context_after_text,
                "translate_text": "\n\n".join([p for p in to_translate if not p.startswith("[IMAGE_")]),
                "has_images": any(p.startswith("[IMAGE_") for p in to_translate)
            }
            
            groups.append(group)
            
        return groups
    
    def _build_context_prompt(self, paragraph_group):
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –∏ —Å–ª–µ–¥—É—é—â–∏—Ö –∞–±–∑–∞—Ü–µ–≤"""
        parts = []
        
        if paragraph_group["context_before"]:
            parts.append("–ö–û–ù–¢–ï–ö–°–¢ –ü–ï–†–ï–î (–ù–ï –ü–ï–†–ï–í–û–î–ò–¢–¨):")
            parts.append("\n\n".join(paragraph_group["context_before"][:2]))  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
            parts.append("")
        
        parts.append("–ü–ï–†–ï–í–ï–î–ò –≠–¢–û:")
        parts.append(paragraph_group["translate_text"])
        
        if paragraph_group["context_after"]:
            parts.append("")
            parts.append("–ö–û–ù–¢–ï–ö–°–¢ –ü–û–°–õ–ï (–ù–ï –ü–ï–†–ï–í–û–î–ò–¢–¨):")
            parts.append("\n\n".join(paragraph_group["context_after"][:2]))  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
        
        return "\n".join(parts)
    
    def _create_system_prompt(self, context):
        prompt = f"""–ü–µ—Ä–µ–≤–æ–¥—á–∏–∫ CMMI –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ EN‚ÜíRU. –§–æ—Ä–º–∞–ª—å–Ω—ã–π —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π —Å—Ç–∏–ª—å, —Ä–æ—Å—Å–∏–π—Å–∫–∞—è IT-—Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—è.
–°–æ—Ö—Ä–∞–Ω—è–π: –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä—ã [IMAGE_XXX], —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ, –∞–±–±—Ä–µ–≤–∏–∞—Ç—É—Ä—ã CMMI/SCAMPI/SEI.
–ö–æ–Ω—Ç–µ–∫—Å—Ç: {context.get('previous_summary', '–ù–∞—á–∞–ª–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞')}"""
        
        return prompt
    
    def _preserve_placeholders(self, text):
        """–ó–∞—â–∏—Ç–∞ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤ –æ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è –ø—Ä–∏ –ø–µ—Ä–µ–≤–æ–¥–µ"""
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä—ã
        self._placeholder_map = {}
        placeholders = re.findall(r'\[IMAGE_[^\]]+\]', text)
        for i, placeholder in enumerate(placeholders):
            marker = f"<<<PLACEHOLDER_{i}>>>"
            self._placeholder_map[marker] = placeholder
            text = text.replace(placeholder, marker)
        return text
    
    def _restore_placeholders(self, text):
        """–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤ –ø–æ—Å–ª–µ –ø–µ—Ä–µ–≤–æ–¥–∞"""
        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä—ã –∏–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–π –∫–∞—Ä—Ç—ã
        if hasattr(self, '_placeholder_map'):
            for marker, original in self._placeholder_map.items():
                text = text.replace(marker, original)
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞ —Å–ª—É—á–∞–π –∏–∑–º–µ–Ω–µ–Ω–∏–π
        # –ï—Å–ª–∏ DeepSeek –≤–µ—Ä–Ω—É–ª –ø—Ä–æ—Å—Ç–æ [IMAGE_0] –≤–º–µ—Å—Ç–æ –ø–æ–ª–Ω–æ–≥–æ ID
        text = re.sub(r'\[IMAGE_(\d+)\]', lambda m: f'[IMAGE_{m.group(1)}]', text)
        # –ù–∞ —Å–ª—É—á–∞–π –µ—Å–ª–∏ DeepSeek –ø–µ—Ä–µ–≤–µ–ª —Å–ª–æ–≤–æ IMAGE
        text = re.sub(r'\[–ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ï[_ ][^\]]+\]', lambda m: m.group(0).replace('–ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ï', 'IMAGE'), text)
        
        return text
    
    def _post_process_formatting(self, text):
        """–ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
        # –£–¥–∞–ª—è–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
        text = re.sub(r'[ \t]+', ' ', text)
        
        # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –≤ –Ω–∞—á–∞–ª–µ –∏ –∫–æ–Ω—Ü–µ —Å—Ç—Ä–æ–∫
        text = re.sub(r'\n[ \t]+', '\n', text)
        text = re.sub(r'[ \t]+\n', '\n', text)
        
        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º —Å–ª—É—á–∞–∏ –≥–¥–µ API –º–æ–≥ –ø–æ—Ç–µ—Ä—è—Ç—å –ø–µ—Ä–µ–Ω–æ—Å—ã –º–µ–∂–¥—É –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º–∏
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–µ—Ä–µ–Ω–æ—Å –ø–µ—Ä–µ–¥ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏ (—Å—Ç—Ä–æ–∫–∏ –∏–∑ 1-3 —Å–ª–æ–≤, –∑–∞–∫–∞–Ω—á–∏–≤–∞—é—â–∏—Ö—Å—è –±–µ–∑ —Ç–æ—á–∫–∏)
        text = re.sub(r'([.!?])\s+([–ê-–ØA-Z][–∞-—èa-z]{1,20}(?:\s+[–ê-–ØA-Z][–∞-—èa-z]{1,20}){0,2})\s+([–ê-–Ø])', 
                     r'\1\n\n\2\n\3', text)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–µ—Ä–µ–Ω–æ—Å—ã –ø–µ—Ä–µ–¥ –Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ —Å–ø–∏—Å–∫–∞–º–∏
        text = re.sub(r'([.!?])\s+(\d+\.\s+[–ê-–Ø])', r'\1\n\n\2', text)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–µ—Ä–µ–Ω–æ—Å—ã –ø–µ—Ä–µ–¥ –º–∞—Ä–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ —Å–ø–∏—Å–∫–∞–º–∏
        text = re.sub(r'([.!?])\s+([-‚Ä¢*]\s+[–ê-–Ø])', r'\1\n\n\2', text)
        
        # –£–±–∏—Ä–∞–µ–º –∏–∑–±—ã—Ç–æ—á–Ω—ã–µ –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ (–±–æ–ª—å—à–µ 3—Ö –ø–æ–¥—Ä—è–¥)
        text = re.sub(r'\n{4,}', '\n\n\n', text)
        
        return text.strip()
    
    def _translate_title(self, title):
        """–ü–µ—Ä–µ–≤–æ–¥ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –≥–ª–∞–≤"""
        translations = {
            "Chapter": "–ì–ª–∞–≤–∞",
            "Part": "–ß–∞—Å—Ç—å",
            "Section": "–†–∞–∑–¥–µ–ª",
            "Introduction": "–í–≤–µ–¥–µ–Ω–∏–µ",
            "Conclusion": "–ó–∞–∫–ª—é—á–µ–Ω–∏–µ",
            "Preface": "–ü—Ä–µ–¥–∏—Å–ª–æ–≤–∏–µ",
            "Appendix": "–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ",
            "References": "–°—Å—ã–ª–∫–∏",
            "Glossary": "–ì–ª–æ—Å—Å–∞—Ä–∏–π",
            "Index": "–ò–Ω–¥–µ–∫—Å"
        }
        
        result = title
        for eng, rus in translations.items():
            result = result.replace(eng, rus)
        
        # –ï—Å–ª–∏ —ç—Ç–æ CMMI-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–π –∑–∞–≥–æ–ª–æ–≤–æ–∫, –æ—Å—Ç–∞–≤–ª—è–µ–º —á–∞—Å—Ç–∏—á–Ω–æ –∫–∞–∫ –µ—Å—Ç—å
        if "CMMI" in result or "Process Area" in result:
            result = result.replace("Process Area", "–û–±–ª–∞—Å—Ç—å –ø—Ä–æ—Ü–µ—Å—Å–æ–≤")
            result = result.replace("Generic Goals", "–û–±—â–∏–µ —Ü–µ–ª–∏")
            result = result.replace("Generic Practices", "–û–±—â–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏")
            result = result.replace("Specific Goals", "–ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ü–µ–ª–∏")
            result = result.replace("Specific Practices", "–ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –ø—Ä–∞–∫—Ç–∏–∫–∏")
        
        return result
    
    def _fallback_translate(self, text):
        """–ó–∞–ø–∞—Å–Ω–æ–π –≤–∞—Ä–∏–∞–Ω—Ç –ø–µ—Ä–µ–≤–æ–¥–∞ –ø—Ä–∏ –æ—à–∏–±–∫–µ API"""
        if text.startswith("[IMAGE_"):
            return text
        
        # –ë–∞–∑–æ–≤—ã–π —Å–ª–æ–≤–∞—Ä–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥
        result = text
        for eng, rus in self.tech_terms.items():
            result = re.sub(r'\b' + eng + r'\b', rus, result, flags=re.IGNORECASE)
        
        return result
    
    def _translate_local(self, chapter_data, context):
        """–õ–æ–∫–∞–ª—å–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥ –±–µ–∑ API"""
        translated_paragraphs = []
        
        for paragraph in chapter_data["paragraphs"]:
            if paragraph.startswith("[IMAGE_"):
                translated_paragraphs.append(paragraph)
            else:
                translated = self._fallback_translate(paragraph)
                translated_paragraphs.append(translated)
        
        return {
            "number": chapter_data["number"],
            "title": self._translate_title(chapter_data["title"]),
            "paragraphs": translated_paragraphs,
            "summary": self._generate_simple_summary(translated_paragraphs),
            "original_word_count": chapter_data["word_count"],
            "translator": "Local"
        }
    
    def _generate_summary(self, paragraphs):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫—Ä–∞—Ç–∫–æ–≥–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è –≥–ª–∞–≤—ã"""
        if not paragraphs:
            return ""
        
        # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤, –∏—Å–∫–ª—é—á–∞—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        text_paragraphs = [p for p in paragraphs[:5] if not p.startswith("[IMAGE_")]
        if text_paragraphs:
            summary = " ".join(text_paragraphs[:2])
            if len(summary) > 500:
                summary = summary[:500] + "..."
            return f"–ö—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ: {summary}"
        
        return "–ì–ª–∞–≤–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –¥–∏–∞–≥—Ä–∞–º–º—ã"
    
    def _generate_simple_summary(self, paragraphs):
        """–ü—Ä–æ—Å—Ç–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∫—Ä–∞—Ç–∫–æ–≥–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è"""
        text_paragraphs = [p for p in paragraphs[:3] if not p.startswith("[IMAGE_")]
        if text_paragraphs:
            summary = " ".join(text_paragraphs[:1])
            if len(summary) > 300:
                summary = summary[:300] + "..."
            return summary
        return ""
    
    def save_translation(self, chapter_num, translation_data):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω–æ–π –≥–ª–∞–≤—ã"""
        filename = f"chapter_{chapter_num:03d}_translated.json"
        filepath = self.translations_dir / filename
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(translation_data, f, ensure_ascii=False, indent=2)
        
        return filepath