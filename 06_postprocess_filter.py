#!/usr/bin/env python3
"""
–ü–æ—Å—Ç-–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ - —É–¥–∞–ª–µ–Ω–∏–µ –Ω–µ–∂–µ–ª–∞—Ç–µ–ª—å–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
–Ω–∞ –æ—Å–Ω–æ–≤–µ —á–µ—Ä–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞ —Å–ª–æ–≤, —Ñ—Ä–∞–∑ –∏ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
"""

import json
import re
import os
import sys
from pathlib import Path
from typing import List, Dict, Set, Tuple
from datetime import datetime
import shutil
from tqdm import tqdm

class TranslationPostProcessor:
    def __init__(self, config_file="blacklist_config.json", 
                 input_dir="translations", 
                 output_dir="translations_filtered"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ—Å—Ç-–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞
        
        Args:
            config_file: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —Å —á–µ—Ä–Ω—ã–º —Å–ø–∏—Å–∫–æ–º
            input_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –∏—Å—Ö–æ–¥–Ω—ã–º–∏ –ø–µ—Ä–µ–≤–æ–¥–∞–º–∏
            output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–µ—Ä–µ–≤–æ–¥–æ–≤
        """
        self.config_file = Path(config_file)
        self.input_dir = Path(input_dir)
        self.output_dir = Path(output_dir)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        self.config = self.load_config()
        
        # –ö–æ–º–ø–∏–ª–∏—Ä—É–µ–º —Ä–µ–≥—É–ª—è—Ä–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
        self.compiled_patterns = self.compile_patterns()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —É–¥–∞–ª–µ–Ω–∏–π
        self.stats = {
            "total_chapters": 0,
            "total_paragraphs": 0,
            "removed_paragraphs": 0,
            "modified_paragraphs": 0,
            "removed_phrases": {},
            "removed_symbols": {},
            "removed_patterns": {}
        }
        
        # –°–æ–∑–¥–∞–µ–º –≤—ã—Ö–æ–¥–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
        self.output_dir.mkdir(exist_ok=True)
        
        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —É–¥–∞–ª–µ–Ω–∏–π
        self.log_file = self.output_dir / "postprocess_log.txt"
        self.log_entries = []
        
    def load_config(self) -> Dict:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏–∑ JSON —Ñ–∞–π–ª–∞"""
        if not self.config_file.exists():
            print(f"‚ö†Ô∏è –§–∞–π–ª –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ {self.config_file} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
            print("   –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é...")
            default_config = {
                "blacklist": {
                    "phrases": [],
                    "symbols": [],
                    "patterns": []
                },
                "settings": {
                    "remove_empty_paragraphs": True,
                    "case_sensitive": False,
                    "trim_whitespace": True,
                    "min_paragraph_length": 10,
                    "log_removals": True
                }
            }
            with open(self.config_file, 'w', encoding='utf-8') as f:
                json.dump(default_config, f, ensure_ascii=False, indent=2)
            return default_config
            
        with open(self.config_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def compile_patterns(self) -> List[Tuple[re.Pattern, str]]:
        """–ö–æ–º–ø–∏–ª–∏—Ä—É–µ—Ç —Ä–µ–≥—É–ª—è—Ä–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
        compiled = []
        patterns = self.config.get("blacklist", {}).get("patterns", [])
        
        for pattern_info in patterns:
            if isinstance(pattern_info, dict):
                pattern_str = pattern_info.get("pattern", "")
                description = pattern_info.get("description", "")
            else:
                pattern_str = pattern_info
                description = pattern_str
            
            if pattern_str:
                flags = 0 if self.config["settings"]["case_sensitive"] else re.IGNORECASE
                try:
                    compiled_pattern = re.compile(pattern_str, flags)
                    compiled.append((compiled_pattern, description))
                except re.error as e:
                    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∫–æ–º–ø–∏–ª—è—Ü–∏–∏ –ø–∞—Ç—Ç–µ—Ä–Ω–∞ '{pattern_str}': {e}")
        
        return compiled
    
    def remove_blacklisted_content(self, text: str, context: str = "") -> str:
        """
        –£–¥–∞–ª—è–µ—Ç –∑–∞–ø—Ä–µ—â–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç –∏–∑ —Ç–µ–∫—Å—Ç–∞
        
        Args:
            text: –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            context: –ö–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, "Chapter 1, Paragraph 5")
            
        Returns:
            –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        """
        if not text:
            return text
        
        original_text = text
        settings = self.config["settings"]
        
        # 1. –£–¥–∞–ª—è–µ–º —Å–∏–º–≤–æ–ª—ã
        for symbol in self.config["blacklist"].get("symbols", []):
            if symbol in text:
                count = text.count(symbol)
                text = text.replace(symbol, "")
                if settings["log_removals"] and count > 0:
                    self.stats["removed_symbols"][symbol] = \
                        self.stats["removed_symbols"].get(symbol, 0) + count
                    self.log_entries.append(
                        f"{context}: –£–¥–∞–ª–µ–Ω —Å–∏–º–≤–æ–ª '{symbol}' ({count} —Ä–∞–∑)"
                    )
        
        # 2. –£–¥–∞–ª—è–µ–º —Ñ—Ä–∞–∑—ã
        for phrase in self.config["blacklist"].get("phrases", []):
            if not settings["case_sensitive"]:
                # –†–µ–≥–∏—Å—Ç—Ä–æ–Ω–µ–∑–∞–≤–∏—Å–∏–º—ã–π –ø–æ–∏—Å–∫
                pattern = re.compile(re.escape(phrase), re.IGNORECASE)
                matches = pattern.findall(text)
                if matches:
                    text = pattern.sub("", text)
                    count = len(matches)
                    self.stats["removed_phrases"][phrase] = \
                        self.stats["removed_phrases"].get(phrase, 0) + count
                    if settings["log_removals"]:
                        self.log_entries.append(
                            f"{context}: –£–¥–∞–ª–µ–Ω–∞ —Ñ—Ä–∞–∑–∞ '{phrase}' ({count} —Ä–∞–∑)"
                        )
            else:
                if phrase in text:
                    count = text.count(phrase)
                    text = text.replace(phrase, "")
                    self.stats["removed_phrases"][phrase] = \
                        self.stats["removed_phrases"].get(phrase, 0) + count
                    if settings["log_removals"]:
                        self.log_entries.append(
                            f"{context}: –£–¥–∞–ª–µ–Ω–∞ —Ñ—Ä–∞–∑–∞ '{phrase}' ({count} —Ä–∞–∑)"
                        )
        
        # 3. –£–¥–∞–ª—è–µ–º –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º
        for pattern, description in self.compiled_patterns:
            matches = pattern.findall(text)
            if matches:
                text = pattern.sub("", text)
                count = len(matches)
                self.stats["removed_patterns"][description] = \
                    self.stats["removed_patterns"].get(description, 0) + count
                if settings["log_removals"]:
                    self.log_entries.append(
                        f"{context}: –£–¥–∞–ª–µ–Ω –ø–∞—Ç—Ç–µ—Ä–Ω '{description}' ({count} —Ä–∞–∑)"
                    )
        
        # 4. –û—á–∏—â–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if settings["trim_whitespace"]:
            # –£–±–∏—Ä–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã
            text = re.sub(r' +', ' ', text)
            # –£–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã –≤ –Ω–∞—á–∞–ª–µ –∏ –∫–æ–Ω—Ü–µ —Å—Ç—Ä–æ–∫
            lines = text.split('\n')
            lines = [line.strip() for line in lines]
            text = '\n'.join(lines)
            # –£–±–∏—Ä–∞–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫
            text = re.sub(r'\n{3,}', '\n\n', text)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∏–∑–º–µ–Ω–∏–ª—Å—è –ª–∏ —Ç–µ–∫—Å—Ç
        if text != original_text:
            self.stats["modified_paragraphs"] += 1
        
        return text
    
    def is_paragraph_empty(self, text: str) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –ø–∞—Ä–∞–≥—Ä–∞—Ñ –ø—É—Å—Ç—ã–º –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        
        Args:
            text: –¢–µ–∫—Å—Ç –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞
            
        Returns:
            True –µ—Å–ª–∏ –ø–∞—Ä–∞–≥—Ä–∞—Ñ –ø—É—Å—Ç–æ–π –∏–ª–∏ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π
        """
        if not text:
            return True
        
        # –£–±–∏—Ä–∞–µ–º –≤—Å–µ whitespace –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
        cleaned = re.sub(r'\s+', '', text)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—É—é –¥–ª–∏–Ω—É
        min_length = self.config["settings"].get("min_paragraph_length", 10)
        
        return len(cleaned) < min_length
    
    def process_chapter(self, chapter_data: Dict, chapter_name: str) -> Dict:
        """
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–Ω—É –≥–ª–∞–≤—É
        
        Args:
            chapter_data: –î–∞–Ω–Ω—ã–µ –≥–ª–∞–≤—ã
            chapter_name: –ò–º—è —Ñ–∞–π–ª–∞ –≥–ª–∞–≤—ã –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
            
        Returns:
            –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≥–ª–∞–≤—ã
        """
        self.stats["total_chapters"] += 1
        
        # –ö–æ–ø–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –≥–ª–∞–≤—ã
        filtered_chapter = {
            "number": chapter_data.get("number", 0),
            "title": chapter_data.get("title", ""),
            "start_page": chapter_data.get("start_page", 0),
            "end_page": chapter_data.get("end_page", 0),
            "paragraphs": []
        }
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
        if filtered_chapter["title"]:
            filtered_chapter["title"] = self.remove_blacklisted_content(
                filtered_chapter["title"],
                f"{chapter_name}: Title"
            )
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã
        paragraphs = chapter_data.get("paragraphs", [])
        
        for idx, paragraph in enumerate(paragraphs):
            self.stats["total_paragraphs"] += 1
            
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            if paragraph and paragraph.startswith('[IMAGE_'):
                filtered_chapter["paragraphs"].append(paragraph)
                continue
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç
            context = f"{chapter_name}, Paragraph {idx + 1}"
            filtered_text = self.remove_blacklisted_content(paragraph, context)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —Å—Ç–∞–ª –ª–∏ –ø–∞—Ä–∞–≥—Ä–∞—Ñ –ø—É—Å—Ç—ã–º
            if self.config["settings"]["remove_empty_paragraphs"]:
                if not self.is_paragraph_empty(filtered_text):
                    filtered_chapter["paragraphs"].append(filtered_text)
                else:
                    self.stats["removed_paragraphs"] += 1
                    if self.config["settings"]["log_removals"]:
                        self.log_entries.append(
                            f"{context}: –ü–∞—Ä–∞–≥—Ä–∞—Ñ —É–¥–∞–ª–µ–Ω (—Å—Ç–∞–ª –ø—É—Å—Ç—ã–º –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏)"
                        )
            else:
                filtered_chapter["paragraphs"].append(filtered_text)
        
        return filtered_chapter
    
    def process_all_translations(self):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—Å–µ —Ñ–∞–π–ª—ã –ø–µ—Ä–µ–≤–æ–¥–æ–≤"""
        print("\nüîç –ü–æ—Å—Ç-–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ –ø–µ—Ä–µ–≤–æ–¥–æ–≤")
        print("=" * 60)
        
        # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —Ñ–∞–π–ª—ã –ø–µ—Ä–µ–≤–æ–¥–æ–≤
        translation_files = sorted(self.input_dir.glob("*_translated.json"))
        
        if not translation_files:
            print(f"‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ –ø–µ—Ä–µ–≤–æ–¥–æ–≤ –≤ {self.input_dir}")
            return False
        
        print(f"üìö –ù–∞–π–¥–µ–Ω–æ –≥–ª–∞–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(translation_files)}")
        print(f"üìã –ó–∞–≥—Ä—É–∂–µ–Ω —á–µ—Ä–Ω—ã–π —Å–ø–∏—Å–æ–∫:")
        print(f"   ‚Ä¢ –§—Ä–∞–∑: {len(self.config['blacklist'].get('phrases', []))}")
        print(f"   ‚Ä¢ –°–∏–º–≤–æ–ª–æ–≤: {len(self.config['blacklist'].get('symbols', []))}")
        print(f"   ‚Ä¢ –ü–∞—Ç—Ç–µ—Ä–Ω–æ–≤: {len(self.config['blacklist'].get('patterns', []))}")
        print()
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—É—é –≥–ª–∞–≤—É
        with tqdm(total=len(translation_files), desc="–û–±—Ä–∞–±–æ—Ç–∫–∞ –≥–ª–∞–≤") as pbar:
            for file_path in translation_files:
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≥–ª–∞–≤—ã
                with open(file_path, 'r', encoding='utf-8') as f:
                    chapter_data = json.load(f)
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≥–ª–∞–≤—É
                filtered_chapter = self.process_chapter(
                    chapter_data, 
                    file_path.stem
                )
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—É—é –≥–ª–∞–≤—É
                output_file = self.output_dir / file_path.name
                with open(output_file, 'w', encoding='utf-8') as f:
                    json.dump(filtered_chapter, f, ensure_ascii=False, indent=2)
                
                pbar.update(1)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª–æ–≥
        if self.config["settings"]["log_removals"] and self.log_entries:
            with open(self.log_file, 'w', encoding='utf-8') as f:
                f.write(f"–õ–æ–≥ –ø–æ—Å—Ç-–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞ –æ—Ç {datetime.now().isoformat()}\n")
                f.write("=" * 60 + "\n\n")
                for entry in self.log_entries:
                    f.write(entry + "\n")
        
        return True
    
    def print_statistics(self):
        """–í—ã–≤–æ–¥–∏—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        print("\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ—Å—Ç-–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥–∞:")
        print("=" * 60)
        print(f"üìö –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –≥–ª–∞–≤: {self.stats['total_chapters']}")
        print(f"üìù –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤: {self.stats['total_paragraphs']}")
        print(f"‚úèÔ∏è –ò–∑–º–µ–Ω–µ–Ω–æ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤: {self.stats['modified_paragraphs']}")
        print(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–æ –ø—É—Å—Ç—ã—Ö –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤: {self.stats['removed_paragraphs']}")
        
        if self.stats["removed_symbols"]:
            print("\nüî§ –£–¥–∞–ª–µ–Ω–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã:")
            for symbol, count in sorted(self.stats["removed_symbols"].items()):
                print(f"   ‚Ä¢ '{symbol}': {count} —Ä–∞–∑")
        
        if self.stats["removed_phrases"]:
            print("\nüìù –£–¥–∞–ª–µ–Ω–Ω—ã–µ —Ñ—Ä–∞–∑—ã:")
            for phrase, count in sorted(self.stats["removed_phrases"].items()):
                print(f"   ‚Ä¢ '{phrase[:50]}...': {count} —Ä–∞–∑" if len(phrase) > 50 
                      else f"   ‚Ä¢ '{phrase}': {count} —Ä–∞–∑")
        
        if self.stats["removed_patterns"]:
            print("\nüîç –£–¥–∞–ª–µ–Ω–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã:")
            for pattern, count in sorted(self.stats["removed_patterns"].items()):
                print(f"   ‚Ä¢ {pattern}: {count} —Ä–∞–∑")
        
        if self.log_entries and self.config["settings"]["log_removals"]:
            print(f"\nüìã –ü–æ–¥—Ä–æ–±–Ω—ã–π –ª–æ–≥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {self.log_file}")
    
    def backup_original(self):
        """–°–æ–∑–¥–∞–µ—Ç —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–≤–æ–¥–æ–≤"""
        backup_dir = self.input_dir.parent / f"{self.input_dir.name}_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        print(f"\nüíæ –°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑–µ—Ä–≤–Ω–æ–π –∫–æ–ø–∏–∏ –≤ {backup_dir}...")
        shutil.copytree(self.input_dir, backup_dir)
        print(f"‚úÖ –†–µ–∑–µ—Ä–≤–Ω–∞—è –∫–æ–ø–∏—è —Å–æ–∑–¥–∞–Ω–∞")
        
        return backup_dir

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description='–ü–æ—Å—Ç-–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –ø–æ —á–µ—Ä–Ω–æ–º—É —Å–ø–∏—Å–∫—É'
    )
    parser.add_argument(
        '--config',
        default='blacklist_config.json',
        help='–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: blacklist_config.json)'
    )
    parser.add_argument(
        '--input-dir',
        default='translations',
        help='–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å –∏—Å—Ö–æ–¥–Ω—ã–º–∏ –ø–µ—Ä–µ–≤–æ–¥–∞–º–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: translations)'
    )
    parser.add_argument(
        '--output-dir',
        default='translations_filtered',
        help='–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–µ—Ä–µ–≤–æ–¥–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: translations_filtered)'
    )
    parser.add_argument(
        '--no-backup',
        action='store_true',
        help='–ù–µ —Å–æ–∑–¥–∞–≤–∞—Ç—å —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤'
    )
    parser.add_argument(
        '--replace',
        action='store_true',
        help='–ó–∞–º–µ–Ω–∏—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–º–∏'
    )
    
    args = parser.parse_args()
    
    # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
    processor = TranslationPostProcessor(
        config_file=args.config,
        input_dir=args.input_dir,
        output_dir=args.output_dir
    )
    
    # –°–æ–∑–¥–∞–µ–º —Ä–µ–∑–µ—Ä–≤–Ω—É—é –∫–æ–ø–∏—é –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    if not args.no_backup and args.replace:
        processor.backup_original()
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–µ—Ä–µ–≤–æ–¥—ã
    success = processor.process_all_translations()
    
    if success:
        # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        processor.print_statistics()
        
        # –ó–∞–º–µ–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ —Ñ–∞–π–ª—ã –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω–æ
        if args.replace:
            print(f"\nüîÑ –ó–∞–º–µ–Ω–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤...")
            
            # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
            shutil.rmtree(args.input_dir)
            
            # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤—ã–≤–∞–µ–º –Ω–æ–≤—É—é
            Path(args.output_dir).rename(args.input_dir)
            
            print(f"‚úÖ –§–∞–π–ª—ã –∑–∞–º–µ–Ω–µ–Ω—ã")
        else:
            print(f"\n‚úÖ –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–µ—Ä–µ–≤–æ–¥—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {args.output_dir}")
    else:
        print("\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ")
        return 1
    
    return 0

if __name__ == "__main__":
    sys.exit(main())