#!/usr/bin/env python3
"""
–£–ª—É—á—à–µ–Ω–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –º–µ–∂–¥—É –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞–º–∏
"""

import json
import os
import sys
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional
import time
from tqdm import tqdm

from deepseek_translator import DeepSeekTranslator
from translation_manager import TranslationProgress, ContextManager


class ContextualTranslator:
    """–ü–µ—Ä–µ–≤–æ–¥—á–∏–∫ —Å –ø–µ—Ä–µ–¥–∞—á–µ–π –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –º–µ–∂–¥—É –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞–º–∏"""
    
    def __init__(self, source_dir="extracted_proper", translations_dir="translations"):
        self.source_dir = Path(source_dir)
        self.translations_dir = Path(translations_dir)
        self.translations_dir.mkdir(exist_ok=True)
        
        self.translator = DeepSeekTranslator()
        self.progress = TranslationProgress()
        self.context_manager = ContextManager()
        
        # –ö–æ–Ω—Ç–µ–∫—Å—Ç –ø–µ—Ä–µ–≤–æ–¥–∞ - –Ω–∞–∫–∞–ø–ª–∏–≤–∞–µ—Ç—Å—è –ø–æ –º–µ—Ä–µ –ø–µ—Ä–µ–≤–æ–¥–∞
        self.rolling_context = {
            'glossary': {},  # –ù–∞–∫–∞–ø–ª–∏–≤–∞–µ–º—ã–π –≥–ª–æ—Å—Å–∞—Ä–∏–π —Ç–µ—Ä–º–∏–Ω–æ–≤
            'recent_translations': [],  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ N –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã—Ö –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤
            'chapter_summary': '',  # –†–µ–∑—é–º–µ —Ç–µ–∫—É—â–µ–π –≥–ª–∞–≤—ã
            'previous_paragraph': '',  # –ü—Ä–µ–¥—ã–¥—É—â–∏–π –ø–∞—Ä–∞–≥—Ä–∞—Ñ –¥–ª—è —Å–≤—è–∑–Ω–æ—Å—Ç–∏
        }
        
    def translate_book(self):
        """–ü–µ—Ä–µ–≤–æ–¥–∏—Ç –≤—Å—é –∫–Ω–∏–≥—É —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º"""
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–ø–∏—Å–æ–∫ –≥–ª–∞–≤
        chapters = self._load_chapters()
        if not chapters:
            print("‚ùå –ì–ª–∞–≤—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")
            return
        
        print(f"üìö –ù–∞–π–¥–µ–Ω–æ {len(chapters)} –≥–ª–∞–≤ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞")
        
        # –ü–µ—Ä–µ–≤–æ–¥–∏–º –∫–∞–∂–¥—É—é –≥–ª–∞–≤—É
        for chapter_file in tqdm(chapters, desc="–ü–µ—Ä–µ–≤–æ–¥ –≥–ª–∞–≤"):
            chapter_num = self._extract_chapter_num(chapter_file)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–∞ –ª–∏ —É–∂–µ –≥–ª–∞–≤–∞
            if self.progress.is_chapter_translated(chapter_num):
                print(f"‚úÖ –ì–ª–∞–≤–∞ {chapter_num} —É–∂–µ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–∞, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω–æ–π –≥–ª–∞–≤—ã
                self._load_chapter_context(chapter_num)
                continue
            
            print(f"\nüìñ –ü–µ—Ä–µ–≤–æ–¥ –≥–ª–∞–≤—ã {chapter_num}...")
            self._translate_chapter(chapter_file)
        
        print("\n‚ú® –ü–µ—Ä–µ–≤–æ–¥ –∑–∞–≤–µ—Ä—à–µ–Ω!")
    
    def _translate_chapter(self, chapter_file):
        """–ü–µ—Ä–µ–≤–æ–¥–∏—Ç –æ–¥–Ω—É –≥–ª–∞–≤—É —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º"""
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≥–ª–∞–≤—ã
        with open(chapter_file, 'r', encoding='utf-8') as f:
            chapter_data = json.load(f)
        
        chapter_num = chapter_data['number']
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –≥–ª–∞–≤—ã –∏–∑ —Ñ–∞–π–ª–æ–≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        try:
            chapter_context = self.context_manager.load_chapter_context(chapter_num)
        except:
            # –ï—Å–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω, —Å–æ–∑–¥–∞–µ–º –ø—É—Å—Ç–æ–π
            chapter_context = {}
        
        # –û–±–Ω–æ–≤–ª—è–µ–º rolling context
        if chapter_context:
            self.rolling_context['chapter_summary'] = chapter_context.get('summary', '')
        
        # –ü–µ—Ä–µ–≤–æ–¥–∏–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
        translated_title = self._translate_title(chapter_data['title'])
        
        # –ü–µ—Ä–µ–≤–æ–¥–∏–º –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã —Å –ø–µ—Ä–µ–¥–∞—á–µ–π –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        translated_paragraphs = []
        total_paragraphs = len(chapter_data['paragraphs'])
        
        print(f"üìù –ü–µ—Ä–µ–≤–æ–¥–∏–º {total_paragraphs} –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤...")
        
        for idx, paragraph in enumerate(tqdm(chapter_data['paragraphs'], desc="–ü–∞—Ä–∞–≥—Ä–∞—Ñ—ã")):
            
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            if paragraph.startswith("[IMAGE_"):
                translated_paragraphs.append(paragraph)
                continue
            
            # –ü–µ—Ä–µ–≤–æ–¥–∏–º –ø–∞—Ä–∞–≥—Ä–∞—Ñ —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º
            translated = self._translate_paragraph_with_context(
                paragraph, 
                idx, 
                total_paragraphs,
                chapter_context
            )
            
            translated_paragraphs.append(translated)
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
            self._update_rolling_context(paragraph, translated)
            
            # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –ø–µ—Ä–µ–≥—Ä—É–∑–∫–∏ API
            if idx % 10 == 0 and idx > 0:
                time.sleep(0.5)
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∑—é–º–µ –≥–ª–∞–≤—ã
        summary = self._generate_chapter_summary(translated_paragraphs)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–µ—Ä–µ–≤–æ–¥
        translation = {
            "number": chapter_num,
            "title": translated_title,
            "paragraphs": translated_paragraphs,
            "summary": summary,
            "original_word_count": chapter_data.get('word_count', 0),
            "translator": "Contextual DeepSeek",
            "translation_date": datetime.now().isoformat()
        }
        
        output_file = self.translations_dir / f"chapter_{chapter_num:03d}_translated.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(translation, f, ensure_ascii=False, indent=2)
        
        # –û—Ç–º–µ—á–∞–µ–º –≥–ª–∞–≤—É –∫–∞–∫ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—É—é
        self.progress.mark_chapter_complete(chapter_num)
        
        print(f"‚úÖ –ì–ª–∞–≤–∞ {chapter_num} –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–∞!")
    
    def _translate_paragraph_with_context(self, paragraph, idx, total, chapter_context):
        """–ü–µ—Ä–µ–≤–æ–¥–∏—Ç –ø–∞—Ä–∞–≥—Ä–∞—Ñ —Å —É—á–µ—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞
        context_prompt = self._build_context_prompt(idx, total, chapter_context)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞
        prompt = f"""{context_prompt}

–ü–µ—Ä–µ–≤–µ–¥–∏ —Å–ª–µ–¥—É—é—â–∏–π –ø–∞—Ä–∞–≥—Ä–∞—Ñ, —É—á–∏—Ç—ã–≤–∞—è –∫–æ–Ω—Ç–µ–∫—Å—Ç:

{paragraph}

–í–ê–ñ–ù–´–ï –¢–†–ï–ë–û–í–ê–ù–ò–Ø:
1. –°–æ—Ö—Ä–∞–Ω—è–π —Å–≤—è–∑–Ω–æ—Å—Ç—å —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º —Ç–µ–∫—Å—Ç–æ–º
2. –ò—Å–ø–æ–ª—å–∑—É–π —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—É—é —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—é –∏–∑ –≥–ª–æ—Å—Å–∞—Ä–∏—è
3. –°–æ—Ö—Ä–∞–Ω—è–π —Å—Ç–∏–ª—å –∏ —Ç–æ–Ω –¥–æ–∫—É–º–µ–Ω—Ç–∞
4. –ù–ï –¥–æ–±–∞–≤–ª—è–π –æ–±—ä—è—Å–Ω–µ–Ω–∏—è –∏–ª–∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
5. –í–æ–∑–≤—Ä–∞—â–∞–π –¢–û–õ–¨–ö–û –ø–µ—Ä–µ–≤–æ–¥

–ü–µ—Ä–µ–≤–æ–¥:"""
        
        try:
            response = self.translator.client.chat.completions.create(
                model="deepseek-chat",
                messages=[
                    {"role": "system", "content": self._get_system_prompt()},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=2000,
                temperature=0.3,
            )
            
            translated = response.choices[0].message.content.strip()
            
            # –û—á–∏—Å—Ç–∫–∞ –æ—Ç –≤–æ–∑–º–æ–∂–Ω—ã—Ö –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤
            translated = self._clean_translation(translated)
            
            return translated
            
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–≤–æ–¥–µ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞ {idx}: {e}")
            # Fallback –Ω–∞ –ø—Ä–æ—Å—Ç–æ–π –ø–µ—Ä–µ–≤–æ–¥
            return self.translator._fallback_translate(paragraph)
    
    def _build_context_prompt(self, idx, total, chapter_context):
        """–°—Ç—Ä–æ–∏—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞"""
        
        context_parts = []
        
        # –ü–æ–∑–∏—Ü–∏—è –≤ –≥–ª–∞–≤–µ
        position = "–Ω–∞—á–∞–ª–µ" if idx < total * 0.3 else "—Å–µ—Ä–µ–¥–∏–Ω–µ" if idx < total * 0.7 else "–∫–æ–Ω—Ü–µ"
        context_parts.append(f"–ü–æ–∑–∏—Ü–∏—è –≤ –≥–ª–∞–≤–µ: {position} ({idx+1}/{total})")
        
        # –ü—Ä–µ–¥—ã–¥—É—â–∏–π –ø–∞—Ä–∞–≥—Ä–∞—Ñ –¥–ª—è —Å–≤—è–∑–Ω–æ—Å—Ç–∏
        if self.rolling_context['previous_paragraph']:
            context_parts.append(f"–ü—Ä–µ–¥—ã–¥—É—â–∏–π –ø–∞—Ä–∞–≥—Ä–∞—Ñ: ...{self.rolling_context['previous_paragraph'][-200:]}")
        
        # –ì–ª–æ—Å—Å–∞—Ä–∏–π –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤
        if self.rolling_context['glossary']:
            terms = list(self.rolling_context['glossary'].items())[:20]  # –¢–æ–ø-20 —Ç–µ—Ä–º–∏–Ω–æ–≤
            terms_str = ", ".join([f"{en}: {ru}" for en, ru in terms])
            context_parts.append(f"–ò—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ —Ç–µ—Ä–º–∏–Ω—ã: {terms_str}")
        
        # –ö–æ–Ω—Ç–µ–∫—Å—Ç –≥–ª–∞–≤—ã
        if chapter_context:
            if 'key_concepts' in chapter_context:
                context_parts.append(f"–ö–ª—é—á–µ–≤—ã–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏ –≥–ª–∞–≤—ã: {', '.join(chapter_context['key_concepts'][:5])}")
            if 'summary' in chapter_context:
                context_parts.append(f"–û —á–µ–º –≥–ª–∞–≤–∞: {chapter_context['summary'][:200]}")
        
        return "\n".join(context_parts)
    
    def _update_rolling_context(self, original, translated):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –Ω–∞–∫–∞–ø–ª–∏–≤–∞–µ–º—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç"""
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π –ø–∞—Ä–∞–≥—Ä–∞—Ñ
        self.rolling_context['previous_paragraph'] = translated
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é –ø–µ—Ä–µ–≤–æ–¥–æ–≤ (—Ö—Ä–∞–Ω–∏–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 5)
        self.rolling_context['recent_translations'].append(translated)
        if len(self.rolling_context['recent_translations']) > 5:
            self.rolling_context['recent_translations'].pop(0)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏ –æ–±–Ω–æ–≤–ª—è–µ–º —Ç–µ—Ä–º–∏–Ω—ã
        self._extract_and_update_terms(original, translated)
    
    def _extract_and_update_terms(self, original, translated):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ—Ä–º–∏–Ω—ã –∏–∑ –ø–µ—Ä–µ–≤–æ–¥–∞ –∏ –æ–±–Ω–æ–≤–ª—è–µ—Ç –≥–ª–æ—Å—Å–∞—Ä–∏–π"""
        
        # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞: –∏—â–µ–º —Å–ª–æ–≤–∞ —Å –∑–∞–≥–ª–∞–≤–Ω–æ–π –±—É–∫–≤—ã (–∫—Ä–æ–º–µ –Ω–∞—á–∞–ª–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)
        import re
        
        # –ê–Ω–≥–ª–∏–π—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã
        en_terms = re.findall(r'(?<![.!?]\s)\b[A-Z][a-z]+(?:\s+[A-Z][a-z]+)*\b', original)
        
        # –†—É—Å—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã (–ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ø–æ –ø–æ–∑–∏—Ü–∏–∏)
        ru_terms = re.findall(r'(?<![.!?]\s)\b[–ê-–Ø–Å][–∞-—è—ë]+(?:\s+[–ê-–Ø–Å][–∞-—è—ë]+)*\b', translated)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –≥–ª–æ—Å—Å–∞—Ä–∏–π (–ø—Ä–æ—Å—Ç–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ)
        for en_term in en_terms[:3]:  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 3 —Ç–µ—Ä–º–∏–Ω–∞
            if en_term not in self.rolling_context['glossary'] and en_term not in ['The', 'This', 'That']:
                # –ü—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –≤ —Ä—É—Å—Å–∫–æ–º —Ç–µ–∫—Å—Ç–µ
                for ru_term in ru_terms:
                    if len(ru_term) > 3:  # –§–∏–ª—å—Ç—Ä—É–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–ª–æ–≤–∞
                        self.rolling_context['glossary'][en_term] = ru_term
                        break
    
    def _translate_title(self, title):
        """–ü–µ—Ä–µ–≤–æ–¥–∏—Ç –∑–∞–≥–æ–ª–æ–≤–æ–∫ –≥–ª–∞–≤—ã"""
        
        prompt = f"""–ü–µ—Ä–µ–≤–µ–¥–∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫ –≥–ª–∞–≤—ã —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏:

{title}

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
- –°–æ—Ö—Ä–∞–Ω–∏ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π —Å—Ç–∏–ª—å
- –ò—Å–ø–æ–ª—å–∑—É–π –ø—Ä–∏–Ω—è—Ç—É—é —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—é
- –ë—É–¥—å –ª–∞–∫–æ–Ω–∏—á–Ω—ã–º

–ü–µ—Ä–µ–≤–æ–¥:"""
        
        try:
            response = self.translator.client.chat.completions.create(
                model="deepseek-chat",
                messages=[
                    {"role": "system", "content": self._get_system_prompt()},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=200,
                temperature=0.3,
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–≤–æ–¥–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞: {e}")
            return self.translator._fallback_translate(title)
    
    def _generate_chapter_summary(self, paragraphs):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ –≥–ª–∞–≤—ã"""
        
        # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ –∏ –ø–æ—Å–ª–µ–¥–Ω–∏–µ –ø–∞—Ä–∞–≥—Ä–∞—Ñ—ã –¥–ª—è —Ä–µ–∑—é–º–µ
        sample_text = []
        
        # –ü–µ—Ä–≤—ã–µ 3 –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞
        for p in paragraphs[:3]:
            if not p.startswith("[IMAGE_"):
                sample_text.append(p)
        
        # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 2 –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞
        for p in paragraphs[-2:]:
            if not p.startswith("[IMAGE_"):
                sample_text.append(p)
        
        if not sample_text:
            return "–ì–ª–∞–≤–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–µ–Ω–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"
        
        text_for_summary = "\n".join(sample_text[:5])  # –ú–∞–∫—Å–∏–º—É–º 5 –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤
        
        prompt = f"""–ù–∞ –æ—Å–Ω–æ–≤–µ —Å–ª–µ–¥—É—é—â–∏—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ —Å–æ–∑–¥–∞–π –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ –≥–ª–∞–≤—ã (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è):

{text_for_summary[:1500]}

–†–µ–∑—é–º–µ:"""
        
        try:
            response = self.translator.client.chat.completions.create(
                model="deepseek-chat",
                messages=[
                    {"role": "system", "content": "–¢—ã —Å–æ–∑–¥–∞–µ—à—å –∫—Ä–∞—Ç–∫–∏–µ —Ä–µ–∑—é–º–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –≥–ª–∞–≤."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=150,
                temperature=0.5,
            )
            
            return response.choices[0].message.content.strip()
            
        except:
            return "–†–µ–∑—é–º–µ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ"
    
    def _get_system_prompt(self):
        """–°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫–∞"""
        return """–¢—ã –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–∏ CMMI.
        
–¢–≤–æ—è –∑–∞–¥–∞—á–∞ - —Å–æ–∑–¥–∞–≤–∞—Ç—å —Ç–æ—á–Ω—ã–µ, —á–∏—Ç–∞–µ–º—ã–µ –ø–µ—Ä–µ–≤–æ–¥—ã —Å –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ –Ω–∞ —Ä—É—Å—Å–∫–∏–π.

–ö–ª—é—á–µ–≤—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã:
1. –°–æ—Ö—Ä–∞–Ω—è–π —Ç–µ—Ö–Ω–∏—á–µ—Å–∫—É—é —Ç–æ—á–Ω–æ—Å—Ç—å
2. –ò—Å–ø–æ–ª—å–∑—É–π –ø—Ä–∏–Ω—è—Ç—É—é —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—É—é —Ç–µ—Ä–º–∏–Ω–æ–ª–æ–≥–∏—é
3. –û–±–µ—Å–ø–µ—á–∏–≤–∞–π —Å–≤—è–∑–Ω–æ—Å—Ç—å —Ç–µ–∫—Å—Ç–∞
4. –ê–¥–∞–ø—Ç–∏—Ä—É–π –¥–ª—è —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω–æ–π –∞—É–¥–∏—Ç–æ—Ä–∏–∏
5. –°–æ—Ö—Ä–∞–Ω—è–π —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É

–°—Ç–∏–ª—å: —Ñ–æ—Ä–º–∞–ª—å–Ω—ã–π, —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π, –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π."""
    
    def _clean_translation(self, text):
        """–û—á–∏—â–∞–µ—Ç –ø–µ—Ä–µ–≤–æ–¥ –æ—Ç –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤"""
        
        # –£–±–∏—Ä–∞–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –º–∞—Ä–∫–µ—Ä—ã
        text = text.replace("–ü–µ—Ä–µ–≤–æ–¥:", "").strip()
        text = text.replace("Translation:", "").strip()
        
        # –£–±–∏—Ä–∞–µ–º –∫–∞–≤—ã—á–∫–∏ –µ—Å–ª–∏ –≤–µ—Å—å —Ç–µ–∫—Å—Ç –≤ –Ω–∏—Ö
        if text.startswith('"') and text.endswith('"'):
            text = text[1:-1]
        
        return text.strip()
    
    def _load_chapters(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –≥–ª–∞–≤"""
        
        chapters = sorted(self.source_dir.glob("chapter_*.json"))
        return chapters
    
    def _extract_chapter_num(self, filepath):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –Ω–æ–º–µ—Ä –≥–ª–∞–≤—ã –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞"""
        
        import re
        match = re.search(r'chapter_(\d+)', filepath.name)
        if match:
            return int(match.group(1))
        return 0
    
    def _load_chapter_context(self, chapter_num):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ —É–∂–µ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω–æ–π –≥–ª–∞–≤—ã"""
        
        trans_file = self.translations_dir / f"chapter_{chapter_num:03d}_translated.json"
        if trans_file.exists():
            with open(trans_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –≥–ª–æ—Å—Å–∞—Ä–∏–π –∏–∑ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω–æ–π –≥–ª–∞–≤—ã
                # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—É—é –ª–æ–≥–∏–∫—É –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ—Ä–º–∏–Ω–æ–≤
                if 'summary' in data:
                    self.rolling_context['chapter_summary'] = data['summary']


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    
    print("üöÄ –ó–∞–ø—É—Å–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫–∞ CMMI...")
    print("=" * 50)
    
    translator = ContextualTranslator()
    
    try:
        translator.translate_book()
        print("\n‚úÖ –ü–µ—Ä–µ–≤–æ–¥ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω!")
        
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è –ü–µ—Ä–µ–≤–æ–¥ –ø—Ä–µ—Ä–≤–∞–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        sys.exit(1)
        
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()