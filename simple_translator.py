#!/usr/bin/env python3
"""
–ü—Ä–æ—Å—Ç–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫ –¥–ª—è –º–µ–¥–ª–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
"""

import json
import requests
from pathlib import Path
import time
from tqdm import tqdm

def translate_text(text, max_retries=3):
    """–ü–µ—Ä–µ–≤–æ–¥–∏—Ç —Ç–µ–∫—Å—Ç —á–µ—Ä–µ–∑ Ollama API —Å –º–µ–Ω—å—à–∏–º–∏ —á–∞–Ω–∫–∞–º–∏"""
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    env_settings = {}
    if Path('.env').exists():
        with open('.env') as f:
            for line in f:
                if '=' in line and not line.startswith('#'):
                    key, val = line.strip().split('=', 1)
                    env_settings[key] = val.strip('"\'')
    
    model = env_settings.get('OLLAMA_MODEL', 'llama3.1:8b')
    
    # –ü—Ä–æ—Å—Ç–æ–π –ø—Ä–æ–º–ø—Ç
    prompt = f"""Translate this text from English to Russian. Keep it natural and professional:

{text}

Russian translation:"""
    
    for attempt in range(max_retries):
        try:
            response = requests.post(
                'http://localhost:11434/api/generate',
                json={
                    'model': model,
                    'prompt': prompt,
                    'stream': False,
                    'temperature': 0.3,
                    'options': {
                        'num_predict': len(text) * 3,  # –†—É—Å—Å–∫–∏–π —Ç–µ–∫—Å—Ç –æ–±—ã—á–Ω–æ –¥–ª–∏–Ω–Ω–µ–µ
                        'top_p': 0.9,
                        'top_k': 40
                    }
                },
                timeout=600  # 10 –º–∏–Ω—É—Ç –Ω–∞ –±–ª–æ–∫
            )
            
            if response.status_code == 200:
                result = response.json()
                return result.get('response', '')
            else:
                print(f"–û—à–∏–±–∫–∞ API: {response.status_code}")
                
        except requests.exceptions.Timeout:
            print(f"–¢–∞–π–º–∞—É—Ç, –ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries}")
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞: {e}")
    
    return None

def main():
    print("=" * 60)
    print("–ü–†–û–°–¢–û–ô –ü–ï–†–ï–í–û–î–ß–ò–ö –î–õ–Ø LLAMA")
    print("=" * 60)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≥–ª–∞–≤—É
    chapter_path = Path('extracted_fixed/chapter_000.json')
    if not chapter_path.exists():
        print("‚ùå –§–∞–π–ª extracted_fixed/chapter_000.json –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return
    
    with open(chapter_path, 'r', encoding='utf-8') as f:
        chapter_data = json.load(f)
    
    paragraphs = chapter_data['paragraphs']
    print(f"üìö –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(paragraphs)} –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤")
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ 300 —Å–∏–º–≤–æ–ª–æ–≤ (–º–µ–Ω—å—à–∏–µ –±–ª–æ–∫–∏)
    groups = []
    current_group = []
    current_size = 0
    max_chars = 300  # –ú–µ–Ω—å—à–∏–µ –±–ª–æ–∫–∏ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞
    
    for para in paragraphs:
        if current_size + len(para) > max_chars and current_group:
            groups.append('\n\n'.join(current_group))
            current_group = [para]
            current_size = len(para)
        else:
            current_group.append(para)
            current_size += len(para)
    
    if current_group:
        groups.append('\n\n'.join(current_group))
    
    print(f"üì¶ –°–æ–∑–¥–∞–Ω–æ {len(groups)} –±–ª–æ–∫–æ–≤ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞")
    print(f"üìè –†–∞–∑–º–µ—Ä –±–ª–æ–∫–∞: ~{max_chars} —Å–∏–º–≤–æ–ª–æ–≤")
    
    # –ü–µ—Ä–µ–≤–æ–¥–∏–º
    translated_blocks = []
    start_time = time.time()
    
    print("\nüöÄ –ù–∞—á–∏–Ω–∞–µ–º –ø–µ—Ä–µ–≤–æ–¥...")
    for i, block in enumerate(tqdm(groups, desc="–ü–µ—Ä–µ–≤–æ–¥")):
        print(f"\nüìù –ë–ª–æ–∫ {i+1}/{len(groups)} ({len(block)} —Å–∏–º–≤.)")
        
        translation = translate_text(block)
        if translation:
            translated_blocks.append(translation)
            print(f"‚úÖ –ü–µ—Ä–µ–≤–µ–¥–µ–Ω–æ: {translation[:50]}...")
        else:
            print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–µ—Ä–µ–≤–µ—Å—Ç–∏ –±–ª–æ–∫ {i+1}")
            translated_blocks.append(block)  # –û—Å—Ç–∞–≤–ª—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 10 –±–ª–æ–∫–æ–≤
        if (i + 1) % 10 == 0:
            save_progress(translated_blocks, i + 1, len(groups))
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    elapsed = time.time() - start_time
    output_dir = Path('translations')
    output_dir.mkdir(exist_ok=True)
    
    translation = {
        'chapter_num': 0,
        'title': chapter_data.get('title', 'Chapter 1'),
        'paragraphs': translated_blocks,
        'translation_time': elapsed,
        'blocks_count': len(groups)
    }
    
    output_file = output_dir / 'chapter_000_simple.json'
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(translation, f, ensure_ascii=False, indent=2)
    
    print(f"\n‚úÖ –ü–µ—Ä–µ–≤–æ–¥ –∑–∞–≤–µ—Ä—à–µ–Ω!")
    print(f"‚è±Ô∏è  –í—Ä–µ–º—è: {elapsed/60:.1f} –º–∏–Ω—É—Ç")
    print(f"üìÑ –§–∞–π–ª: {output_file}")
    print(f"üìä –°—Ä–µ–¥–Ω—è—è —Å–∫–æ—Ä–æ—Å—Ç—å: {elapsed/len(groups):.1f} —Å–µ–∫/–±–ª–æ–∫")

def save_progress(blocks, current, total):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π –ø—Ä–æ–≥—Ä–µ—Å—Å"""
    progress_dir = Path('progress')
    progress_dir.mkdir(exist_ok=True)
    
    progress_file = progress_dir / 'translation_progress.json'
    with open(progress_file, 'w', encoding='utf-8') as f:
        json.dump({
            'blocks': blocks,
            'current': current,
            'total': total,
            'timestamp': time.time()
        }, f, ensure_ascii=False, indent=2)
    
    print(f"üíæ –ü—Ä–æ–≥—Ä–µ—Å—Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {current}/{total}")

if __name__ == '__main__':
    main()